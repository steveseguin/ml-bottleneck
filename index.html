<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ML System Bottleneck Analyzer - Hardware Performance Analysis Tool</title>
    
    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAzMiAzMiI+CiAgPGRlZnM+CiAgICA8bGluZWFyR3JhZGllbnQgaWQ9ImdyYWQiIHgxPSIwJSIgeTE9IjAlIiB4Mj0iMTAwJSIgeTI9IjEwMCUiPgogICAgICA8c3RvcCBvZmZzZXQ9IjAlIiBzdHlsZT0ic3RvcC1jb2xvcjojNjM2NmYxO3N0b3Atb3BhY2l0eToxIiAvPgogICAgICA8c3RvcCBvZmZzZXQ9IjEwMCUiIHN0eWxlPSJzdG9wLWNvbG9yOiM0ZjQ2ZTU7c3RvcC1vcGFjaXR5OjEiIC8+CiAgICA8L2xpbmVhckdyYWRpZW50PgogIDwvZGVmcz4KICA8cmVjdCB4PSI0IiB5PSI0IiB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHJ4PSI0IiBmaWxsPSJ1cmwoI2dyYWQpIi8+CiAgPHBhdGggZD0iTTEwIDE2IEwxNCAyMCBMMjIgMTIiIHN0cm9rZT0id2hpdGUiIHN0cm9rZS13aWR0aD0iMiIgZmlsbD0ibm9uZSIvPgogIDxwYXRoIGQ9Ik04IDIyIEwyNCAyMiIgc3Ryb2tlPSJ3aGl0ZSIgc3Ryb2tlLXdpZHRoPSIyIiBmaWxsPSJub25lIi8+CiAgPHBhdGggZD0iTTggMjYgTDIwIDI2IiBzdHJva2U9IndoaXRlIiBzdHJva2Utd2lkdGg9IjEuNSIgZmlsbD0ibm9uZSIgb3BhY2l0eT0iMC43Ii8+Cjwvc3ZnPg==">

    <!-- Primary Meta Tags -->
    <meta name="title" content="ML System Bottleneck Analyzer - Hardware Performance Analysis Tool">
    <meta name="description" content="Analyze and visualize hardware bottlenecks in machine learning systems. Get real-time insights into memory, bandwidth, and compute utilization across multiple devices.">
    <meta name="keywords" content="ML, machine learning, hardware bottleneck, performance analysis, GPU, CPU, token rate, memory utilization, bandwidth analysis, compute utilization">
    <meta name="author" content="Steve Seguin">
    <meta name="theme-color" content="#6366f1">

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://mlbottleneck.com/">
    <meta property="og:title" content="ML System Bottleneck Analyzer">
    <meta property="og:description" content="Web-based tool for analyzing hardware bottlenecks in ML systems. Visualize performance limitations across distributed setups - right in your browser!">
    <meta property="og:image" content="https://mlbottleneck.com/logo.png">

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://mlbottleneck.com/">
    <meta property="twitter:title" content="ML System Bottleneck Analyzer">
    <meta property="twitter:description" content="Web-based tool for analyzing hardware bottlenecks in ML systems. Visualize performance limitations across distributed setups - right in your browser!">
    <meta property="twitter:image" content="https://mlbottleneck.com/logo.png">
    <meta name="twitter:creator" content="@xyster">

    <!-- Additional Meta -->
    <meta name="application-name" content="ML Bottleneck Analyzer">
    <meta name="apple-mobile-web-app-title" content="ML Bottleneck">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="default">
    <meta name="format-detection" content="telephone=no">
    <meta name="mobile-web-app-capable" content="yes">

    <!-- Preload Critical Resources -->
    <link rel="preconnect" href="https://cdnjs.cloudflare.com">

    <!-- Chart.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/3.7.0/chart.min.js"></script>
	<!-- Structured Data for Google -->
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "WebApplication",
      "name": "ML System Bottleneck Analyzer",
      "description": "Web-based tool for analyzing hardware bottlenecks in machine learning systems. Visualize performance limitations across distributed setups - right in your browser!",
      "url": "https://mlbottleneck.com",
      "author": {
        "@type": "Person",
        "name": "Steve Seguin"
      },
      "applicationCategory": "Machine Learning Tools",
      "operatingSystem": "Any",
      "browserRequirements": "Requires JavaScript",
      "offers": {
        "@type": "Offer",
        "price": "0",
        "priceCurrency": "USD"
      }
    }
    </script>
    <style>
	
@media (prefers-color-scheme: dark) {
:root {
    --primary: #6366f1;
    --primary-hover: #4f46e5;
    --destructive: #ef4444;
    --destructive-hover: #dc2626;
    --border: #1e293b;
    --background: #0b0f1a;
    --card: #1e293b;
    --text: #f8fafc;
    --text-secondary: #94a3b8;
    --radius: 0.5rem;
    --shadow: 0 4px 6px -1px rgb(0 0 0 / 0.3), 0 2px 4px -2px rgb(0 0 0 / 0.2);
    --transition: all 0.2s cubic-bezier(0.4, 0, 0.2, 1);
}

* {
    box-sizing: border-box;
}

body {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, system-ui, sans-serif;
    margin: 0;
    padding: 2rem;
    max-width: 1400px;
    margin: 0 auto;
    background: var(--background);
    color: var(--text);
    line-height: 1.5;
}

h1 {
    font-size: 2.25rem;
    font-weight: 700;
    margin: 2rem 0;
    background: linear-gradient(135deg, var(--primary), var(--primary-hover));
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    letter-spacing: -0.025em;
}

h2 {
    font-size: 1.5rem;
    font-weight: 600;
    margin: 1.5rem 0;
    color: var(--text);
    letter-spacing: -0.025em;
}

h3 {
    font-size: 1.25rem;
    font-weight: 600;
    margin: 1rem 0;
    color: var(--text);
}

a {
    color: var(--primary);
    text-decoration: none;
    transition: var(--transition);
}

a:hover {
    color: var(--primary-hover);
    text-decoration: underline;
}

.card {
    background: var(--card);
    border: 1px solid var(--border);
    border-radius: var(--radius);
    padding: 1.5rem;
    margin-bottom: 1.5rem;
    box-shadow: var(--shadow);
    transition: var(--transition);
    backdrop-filter: blur(8px);
}

.card:hover {
    transform: translateY(-2px);
    box-shadow: 0 10px 15px -3px rgb(0 0 0 / 0.3), 0 4px 6px -4px rgb(0 0 0 / 0.2);
    border-color: var(--primary);
}

.grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(min(400px, 100%), 1fr));
    gap: 1.5rem;
    margin: 2rem 0;
}

.device {
    background: var(--background);
    border: 1px solid var(--border);
    padding: 1.5rem;
    margin-bottom: 1rem;
    border-radius: var(--radius);
    transition: var(--transition);
}

.device:hover {
    border-color: var(--primary);
    transform: translateY(-1px);
}

.button {
    background: var(--primary);
    color: white;
    border: none;
    padding: 0.75rem 1.5rem;
    border-radius: var(--radius);
    cursor: pointer;
    font-weight: 500;
    transition: var(--transition);
    font-size: 0.875rem;
    line-height: 1.25rem;
}

.button:hover {
    background: var(--primary-hover);
    transform: translateY(-1px);
}

.button:active {
    transform: translateY(0);
}

.button:disabled {
    opacity: 0.5;
    cursor: not-allowed;
}

.button-destructive {
    background: var(--destructive);
}

.button-destructive:hover {
    background: var(--destructive-hover);
}

.input, select {
    width: 100%;
    padding: 0.75rem;
    border: 1px solid var(--border);
    border-radius: var(--radius);
    margin-bottom: 1rem;
    transition: var(--transition);
    color: var(--text);
    background: var(--background);
    font-size: 0.875rem;
    line-height: 1.25rem;
}

.input:hover, select:hover {
    border-color: var(--primary);
}

.input:focus, select:focus {
    outline: none;
    border-color: var(--primary);
    box-shadow: 0 0 0 3px rgba(99, 102, 241, 0.1);
}

.input:disabled, select:disabled {
    background: #334155;
    cursor: not-allowed;
    opacity: 0.75;
}

.alert {
    background: #881337;
    border: 1px solid var(--destructive);
    padding: 1.5rem;
    border-radius: var(--radius);
    margin-bottom: 1.5rem;
    color: #fecdd3;
}

.device-grid {
    display: grid;
    grid-template-columns: repeat(2, 1fr);
    gap: 1rem;
}

label {
    display: block;
    margin-bottom: 0.5rem;
    font-size: 0.875rem;
    font-weight: 500;
    color: var(--text-secondary);
}

.chart-container {
    height: 400px;
    margin-bottom: 1.5rem;
    padding: 1rem;
    background: var(--background);
    border-radius: var(--radius);
    border: 1px solid var(--border);
    transition: var(--transition);
}

.chart-container:hover {
    border-color: var(--primary);
}

.inline-select-group {
    display: flex;
    gap: 1rem;
    margin-bottom: 1rem;
    align-items: center;
}

.inline-select-group label {
    margin-bottom: 0;
    margin-right: 0.5rem;
    flex-shrink: 0;
    width: auto;
    white-space: nowrap;
}

.inline-select-group select {
    flex-grow: 1;
    margin-bottom: 0;
    min-width: 0;
}

table {
    width: 100%;
    margin: 1.5rem 0;
    border-collapse: separate;
    border-spacing: 0;
    border: 1px solid var(--border);
    border-radius: var(--radius);
    overflow: hidden;
    background: var(--card);
}

th, td {
    padding: 0.75rem 1rem;
    text-align: left;
    border-bottom: 1px solid var(--border);
    font-size: 0.875rem;
}

th {
    background: var(--background);
    font-weight: 600;
    position: relative;
    cursor: pointer;
    user-select: none;
    transition: var(--transition);
}

th:hover {
    background: #334155;
}

th::after {
    content: '';
    position: absolute;
    right: 0.75rem;
    top: 50%;
    transform: translateY(-50%);
    opacity: 0.5;
}

th.asc::after {
    content: '▲';
}

th.desc::after {
    content: '▼';
}

tr:last-child td {
    border-bottom: none;
}

tr:nth-child(even) {
    background-color: rgba(30, 41, 59, 0.5);
}

tr:hover {
    background-color: rgba(99, 102, 241, 0.1);
}

.filters {
    margin: 1.5rem 0;
    display: flex;
    gap: 1rem;
    flex-wrap: wrap;
    background: var(--card);
    padding: 1.5rem;
    border-radius: var(--radius);
    border: 1px solid var(--border);
}

.filter-group {
    display: flex;
    flex-direction: column;
    gap: 0.5rem;
    flex: 1;
    min-width: 200px;
}

@media (max-width: 768px) {
    body {
        padding: 1rem;
    }

    .grid {
        grid-template-columns: 1fr;
    }

    .device-grid {
        grid-template-columns: 1fr;
    }

    .inline-select-group {
        flex-direction: column;
        gap: 0.5rem;
    }

    .inline-select-group select {
        width: 100%;
    }

    .filters {
        flex-direction: column;
    }

    .filter-group {
        width: 100%;
    }

    h1 {
        font-size: 1.75rem;
    }

    h2 {
        font-size: 1.25rem;
    }
}
}
@media (prefers-color-scheme: light) {
 :root {
    --primary: #6366f1;
    --primary-hover: #4f46e5;
    --destructive: #ef4444;
    --destructive-hover: #dc2626;
    --border: #e2e8f0;
    --background: #ffffff;
    --card: #ffffff;
    --text: #0f172a;
    --text-secondary: #475569;
    --radius: 0.75rem;
    --shadow: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);
}

body {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, system-ui, sans-serif;
    margin: 0;
    padding: 2rem;
    max-width: 1400px;
    margin: 0 auto;
    background: #f8fafc;
    color: var(--text);
}

h1 {
    font-size: 2.25rem;
    font-weight: 700;
    margin-bottom: 2rem;
    background: linear-gradient(to right, var(--primary), var(--primary-hover));
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
}

h2 {
    font-size: 1.5rem;
    font-weight: 600;
    margin-bottom: 1.5rem;
    color: var(--text);
}

h3 {
    font-size: 1.25rem;
    font-weight: 600;
    margin-bottom: 1rem;
    color: var(--text);
}

.card {
    background: var(--card);
    border: 1px solid var(--border);
    border-radius: var(--radius);
    padding: 1.5rem;
    margin-bottom: 1.5rem;
    box-shadow: var(--shadow);
    transition: transform 0.2s, box-shadow 0.2s;
}

.card:hover {
    transform: translateY(-2px);
    box-shadow: 0 10px 15px -3px rgb(0 0 0 / 0.1), 0 4px 6px -4px rgb(0 0 0 / 0.1);
}

.grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
    gap: 1.5rem;
}

.device {
    background: var(--background);
    border: 1px solid var(--border);
    padding: 1.5rem;
    margin-bottom: 1rem;
    border-radius: var(--radius);
    transition: border-color 0.2s;
}

.device:hover {
    border-color: var(--primary);
}

.button {
    background: var(--primary);
    color: white;
    border: none;
    padding: 0.75rem 1.5rem;
    border-radius: var(--radius);
    cursor: pointer;
    font-weight: 500;
    transition: background-color 0.2s;
}

.button:hover {
    background: var(--primary-hover);
}

.button-destructive {
    background: var(--destructive);
}

.button-destructive:hover {
    background: var(--destructive-hover);
}

.input, select {
    width: 100%;
    padding: 0.75rem;
    border: 1px solid var(--border);
    border-radius: var(--radius);
    margin-bottom: 1rem;
    transition: border-color 0.2s, box-shadow 0.2s;
    color: var(--text);
    background: var(--background);
}

.input:focus, select:focus {
    outline: none;
    border-color: var(--primary);
    box-shadow: 0 0 0 3px rgba(99, 102, 241, 0.1);
}

.input:disabled, select:disabled {
    background: #f1f5f9;
    cursor: not-allowed;
}

.alert {
    background: #fef2f2;
    border: 1px solid var(--destructive);
    padding: 1.5rem;
    border-radius: var(--radius);
    margin-bottom: 1.5rem;
    color: var(--destructive);
}

.device-grid {
    display: grid;
    grid-template-columns: repeat(2, 1fr);
    gap: 1rem;
}

label {
    display: block;
    margin-bottom: 0.5rem;
    font-size: 0.875rem;
    font-weight: 500;
    color: var(--text-secondary);
}

.chart-container {
    height: 400px;
    margin-bottom: 1.5rem;
    padding: 1rem;
    background: var(--background);
    border-radius: var(--radius);
    border: 1px solid var(--border);
}

.inline-select-group {
    display: flex;
    gap: 1rem;
    margin-bottom: 1rem;
    align-items: center;
}

.inline-select-group label {
    margin-bottom: 0;
    margin-right: 0.5rem;
    flex-shrink: 0;
    width: auto;
}

.inline-select-group select {
    flex-grow: 1;
    margin-bottom: 0;
}

table {
	border-collapse: collapse;
	width: 100%;
	margin: 20px 0;
	font-family: Arial, sans-serif;
}
th, td {
	border: 1px solid #ddd;
	padding: 8px;
	text-align: left;
}
th {
	background-color: #f5f5f5;
	position: relative;
	cursor: pointer;
}
th:hover {
	background-color: #eee;
}
th::after {
	content: '';
	position: absolute;
	right: 8px;
	top: 50%;
	transform: translateY(-50%);
}
th.asc::after {
	content: '▲';
}
th.desc::after {
	content: '▼';
}
tr:nth-child(even) {
	background-color: #f9f9f9;
}
.filters {
	margin: 20px 0;
	display: flex;
	gap: 10px;
	flex-wrap: wrap;
}
.filter-group {
	display: flex;
	flex-direction: column;
	gap: 5px;
}
input, select {
	padding: 5px;
	border: 1px solid #ddd;
	border-radius: 4px;
}

.device {
    position: relative;
    transition: all 0.2s ease;
}
.device.custom-device {
    border-color: var(--primary);
    background: rgba(99, 102, 241, 0.05);
}
.custom-badge {
    position: absolute;
    top: 0.5rem;
    right: 0.5rem;
    background: var(--primary);
    color: white;
    font-size: 0.7rem;
    padding: 0.1rem 0.4rem;
    border-radius: 0.25rem;
    opacity: 0.8;
}
.device-actions {
    display: flex;
    gap: 0.5rem;
}
.device-actions button {
    padding: 0.5rem 0.75rem;
    font-size: 0.8rem;
}

@media (max-width: 768px) {
    body {
        padding: 1rem;
    }

    .grid {
        grid-template-columns: 1fr;
    }

    .device-grid {
        grid-template-columns: 1fr;
    }

    .inline-select-group {
        flex-direction: column;
        gap: 0.5rem;
    }

    .inline-select-group select {
        width: 100%;
    }
}
</style>
</head>
<body>
    <h1>ML System Bottleneck Analyzer</h1>

    <div class="grid">
        <div class="card">
            <h2>Model Configuration</h2>
            <div id="modelConfig">
                <div class="inline-select-group">
                    <label for="modelPreset">Model Preset</label>
                    <select id="modelPreset" class="input">
                        <option value="">Custom</option>
                        <option value="llama3_8b" selected>Llama 3 8B</option>
                        <option value="llama3_70b">Llama 3 70B</option>
                        <option value="mistral_7b">Mistral 7B</option>
                        <option value="deepseek_v3">DeepSeek V3 (700B)</option>
                        <option value="large_model_400b">Large Model (400B+)</option>
                        <option value="very_large_model_1t">Very Large Model (1T+)</option>
                    </select>

                    <label for="quantizationType">Quantization</label>
                    <select id="quantizationType" class="input">
                        <option value="q4">Q4</option>
                        <option value="int8">INT8</option>
                        <option value="float16" selected>FP16</option>
                        <option value="bfloat16">BF16</option>
                        <option value="float32">FP32</option>
                    </select>
                </div>

                <label>Total Parameters (B)</label>
                <input type="number" id="totalParamsB" class="input" value="400">

                <label>Batch Size</label>
                <input type="number" id="batchSize" class="input" value="1">

                <label>Sequence Length</label>
                <input type="number" id="seqLength" class="input" value="2048">

                <label>Hidden Size</label>
                <input type="number" id="hiddenSize" class="input" value="16384">

                <label>Number of Layers</label>
                <input type="number" id="numLayers" class="input" value="120">

                <label>Number of Heads</label>
                <input type="number" id="numHeads" class="input" value="128">

                <label style="display: none;">Data Type</label>
                <select id="dtype" class="input" style="display: none;">
                    <option value="float32">float32</option>
                    <option value="bfloat16" selected>bfloat16</option>
                    <option value="float16">float16</option>
                    <option value="int8">int8</option>
                    <option value="q4">q4</option>
                </select>

                <label>Parallelism Strategy</label>
                <select id="parallelismStrategy" class="input">
                    <option value="pipeline">Pipeline Parallelism</option>
                    <option value="tensor">Tensor Parallelism</option>
                </select>
            </div>
        </div>

	<div class="card">
	    <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 1rem;">
	        <h2>Devices</h2>
	    </div>
	    <div id="devices"></div>
	</div>
    </div>
	
    <div id="alerts"></div>

    <div class="grid">
        <div class="card">
            <h2>Resource Utilization</h2>
            <div class="chart-container">
                <canvas id="utilizationChart"></canvas>
            </div>
        </div>

        <div class="card">
            <h2>System Analysis <small>(Token rates are approximations)</small></h2>
            <div id="systemAnalysis"></div>
        </div>
    </div>

    <h1>Real-world results are below for reference</h1>
    <div class="filters">
        <div class="filter-group">
            <label for="modelFilter">Model:</label>
            <input type="text" id="modelFilter" placeholder="Filter models...">
        </div>
        <div class="filter-group">
            <label for="hardwareFilter">Hardware:</label>
            <input type="text" id="hardwareFilter" placeholder="Filter hardware...">
        </div>
        <div class="filter-group">
            <label for="quantizationFilter">Quantization:</label>
            <input type="text" id="quantizationFilter" placeholder="Filter quantization...">
        </div>
    </div>

    <table id="llmTable">
        <thead>
            <tr>
                <th data-sort="model">Model</th>
                <th data-sort="quantization">Quantization</th>
                <th data-sort="framework">Framework</th>
                <th data-sort="hardware">Hardware</th>
                <th data-sort="batchSize">Batch Size</th>
                <th data-sort="seqLength">Sequence Length</th>
                <th data-sort="tokenRateBatch">Token Rate (Batch)</th>
                <th data-sort="tokenRateSingle">Token Rate (Single)</th>
                <th data-sort="source">Source</th>
            </tr>
        </thead>
        <tbody></tbody>
    </table>

    <script>
        const DTYPE_SIZES = {
            'float32': 4,
            'bfloat16': 2,
            'float16': 2,
            'int8': 1,
            'q4': 0.5
        };
	const MODEL_PRESETS = {
	  'llama3_8b': {
	    totalParamsB: 8,
	    hiddenSize: 3072,
	    numLayers: 32,
	    numHeads: 32
	  },
	  'llama3_70b': {
	    totalParamsB: 70,
	    hiddenSize: 8192,
	    numLayers: 80,
	    numHeads: 64
	  },
	  'mistral_7b': {
	    totalParamsB: 7,
	    hiddenSize: 4096,
	    numLayers: 32,
	    numHeads: 32
	  },
	  'mistral_small_3.1_24b': {
	    totalParamsB: 24,
	    hiddenSize: 5120,
	    numLayers: 40,
	    numHeads: 32,
	    numKVHeads: 8,
	    intermediateSize: 32768,
	    maxPositionEmbeddings: 131072,
	    hasVision: true,
	    visionHiddenSize: 1024,
	    visionNumLayers: 24,
	    visionNumHeads: 16
	  },
	  'deepseek_v3_671b': {
	    totalParamsB: 671,
	    hiddenSize: 8192,
	    numLayers: 64,
	    numHeads: 64
	  },
	  'phi3_14b': {
	    totalParamsB: 14,
	    hiddenSize: 5120,
	    numLayers: 32,
	    numHeads: 32,
	    numKVHeads: 8,
	    intermediateSize: 20480
	  },
	  'phi3_3.8b': {
	    totalParamsB: 3.8,
	    hiddenSize: 3072,
	    numLayers: 32,
	    numHeads: 32,
	    numKVHeads: 8,
	    intermediateSize: 12288
	  },
	  'mixtral_8x7b': {
	    totalParamsB: 47,
	    hiddenSize: 4096,
	    numLayers: 32,
	    numHeads: 32,
	    numKVHeads: 8,
	    numExperts: 8,
	    activeExperts: 2
	  },
	  'mixtral_8x22b': {
	    totalParamsB: 141,
	    hiddenSize: 6144,
	    numLayers: 56,
	    numHeads: 48,
	    numKVHeads: 8,
	    numExperts: 8,
	    activeExperts: 2
	  },
	  'gemma_7b': {
	    totalParamsB: 8.5,
	    hiddenSize: 3072,
	    numLayers: 28,
	    numHeads: 16,
	    numKVHeads: 1,
	    intermediateSize: 24576
	  },
	  'gemma_2b': {
	    totalParamsB: 2.5,
	    hiddenSize: 2048,
	    numLayers: 18,
	    numHeads: 8,
	    numKVHeads: 1,
	    intermediateSize: 16384
	  },
	  'gemma3_27b': {
	    totalParamsB: 27,
	    hiddenSize: 5376,
	    numLayers: 62,
	    numHeads: 32,
	    numKVHeads: 16,
	    intermediateSize: 21504,
	    slidingWindow: 1024,
	    hasVision: true,
	    visionHiddenSize: 1152,
	    visionNumLayers: 27,
	    visionNumHeads: 16,
	    imageSize: 896,
	    ropeScalingFactor: 8.0
	  },
	  'yi_34b': {
	    totalParamsB: 34,
	    hiddenSize: 7168,
	    numLayers: 60,
	    numHeads: 56,
	    numKVHeads: 8
	  },
	  'yi_large_200b': {
	    totalParamsB: 200,
	    hiddenSize: 12288,
	    numLayers: 80,
	    numHeads: 96,
	    numKVHeads: 12
	  },
	  'falcon_40b': {
	    totalParamsB: 40,
	    hiddenSize: 8192,
	    numLayers: 60,
	    numHeads: 128,
	    intermediateSize: 22016
	  },
	  'bloom_176b': {
	    totalParamsB: 176,
	    hiddenSize: 14336,
	    numLayers: 70,
	    numHeads: 112,
	    intermediateSize: 57344
	  },
	  'gpt_neox_20b': {
	    totalParamsB: 20,
	    hiddenSize: 6144,
	    numLayers: 44,
	    numHeads: 64
	  },
	  'mpt_30b': {
	    totalParamsB: 30,
	    hiddenSize: 7168,
	    numLayers: 48,
	    numHeads: 64
	  },
	  'vicuna_13b': {
	    totalParamsB: 13,
	    hiddenSize: 5120,
	    numLayers: 40,
	    numHeads: 40
	  },
	  'large_model_400b': {
	    totalParamsB: 400,
	    hiddenSize: 16384,
	    numLayers: 120,
	    numHeads: 128
	  },
	  'very_large_model_1kb': {
	    totalParamsB: 1000,
	    hiddenSize: 32768,
	    numLayers: 200,
	    numHeads: 256
	  }
	};
const DEVICE_TEMPLATES = {
  // NVIDIA GPUs (High-End to Low-End)
  'B200': {
    name: 'NVIDIA B200',
    memoryGB: 192,
    localBandwidthGBps: 4800,
    networkBandwidthGBps: 900 / 8,
    computeTFlops: {
      'float32': 950,
      'float16': 1900,
      'bfloat16': 1900,
      'int8': 3800,
      'q4': 5700
    },
    type: 'GPU'
  },
  'H100': {
    name: 'NVIDIA H100',
    memoryGB: 120,
    localBandwidthGBps: 3350,
    networkBandwidthGBps: 450,
    computeTFlops: {
      'float32': 500,
      'float16': 989,
      'bfloat16': 989,
      'int8': 1979,
      'q4': 2500
    },
    type: 'GPU'
  },
  'A100': {
    name: 'NVIDIA A100',
    memoryGB: 80,
    localBandwidthGBps: 1935,
    networkBandwidthGBps: 300,
    computeTFlops: {
      'float32': 156,
      'float16': 312,
      'bfloat16': 312,
      'int8': 624,
      'q4': 1000
    },
    type: 'GPU'
  },
  'RTX 6000': {
    name: 'NVIDIA RTX 6000',
    memoryGB: 48,
    localBandwidthGBps: 2000,
    networkBandwidthGBps: 100 / 8,
    computeTFlops: {
      'float32': 150,
      'float16': 300,
      'bfloat16': 300,
      'int8': 600,
      'q4': 900
    },
    type: 'GPU'
  },
  'RTX 5090': {
    name: 'RTX 5090',
    memoryGB: 32,
    localBandwidthGBps: 1500,
    networkBandwidthGBps: 64,
    computeTFlops: {
      'float32': 105,
      'float16': 210,
      'int8': 420,
      'q4': 630
    },
    type: 'GPU'
  },
  'DGX Spark': {
    name: 'DGX Spark',
    memoryGB: 128,
    localBandwidthGBps: 273,
    networkBandwidthGBps: 50/8,
    computeTFlops: {
      'float32': 50,
      'float16': 100,
      'int8': 200,
      'q4': 830
    },
    type: 'GPU'
  },
  'RTX 4090': {
    name: 'RTX 4090',
    memoryGB: 24,
    localBandwidthGBps: 1008,
    networkBandwidthGBps: 32,
    computeTFlops: {
      'float32': 83,
      'float16': 166,
      'bfloat16': 83,
      'int8': 332,
      'q4': 500
    },
    type: 'GPU'
  },
  'Titan RTX + NVMe Gen3': {
    name: 'Titan RTX + NVMe Gen3',
    memoryGB: 4000,
    localBandwidthGBps: 3.5,
    networkBandwidthGBps: 1 / 8,
    computeTFlops: {
      'float32': 16.3,
      'float16': 32.6,
      'int8': 65.2,
      'q4': 98
    },
    type: 'GPU/NVMe'
  },
  'RTX 4070': {
    name: 'RTX 4070',
    memoryGB: 12,
    localBandwidthGBps: 504,
    networkBandwidthGBps: 32,
    computeTFlops: {
      'float32': 29,
      'float16': 58,
      'int8': 116,
      'q4': 175
    },
    type: 'GPU'
  },
  'RTX 4060': {
    name: 'NVIDIA RTX 4060 8GB',
    memoryGB: 8,
    localBandwidthGBps: 272,
    networkBandwidthGBps: 16,
    computeTFlops: {
      'float32': 15,
      'float16': 30,
      'bfloat16': 30,
      'int8': 60,
      'q4': 90
    },
    type: 'GPU'
  },
  'RTX 4060 Mobile': {
    name: 'NVIDIA RTX 4060 Mobile 8GB',
    memoryGB: 8,
    localBandwidthGBps: 168,
    networkBandwidthGBps: 8,
    computeTFlops: {
      'float32': 10,
      'float16': 20,
      'bfloat16': 20,
      'int8': 40,
      'q4': 60
    },
    type: 'Mobile GPU'
  },
  'RTX 3060': {
    name: 'NVIDIA RTX 3060 12GB',
    memoryGB: 12,
    localBandwidthGBps: 360,
    networkBandwidthGBps: 16,
    computeTFlops: {
      'float32': 13,
      'float16': 26,
      'bfloat16': 26,
      'int8': 52,
      'q4': 78
    },
    type: 'GPU'
  },
  'RTX 3050': {
    name: 'NVIDIA RTX 3050 8GB',
    memoryGB: 8,
    localBandwidthGBps: 224,
    networkBandwidthGBps: 16,
    computeTFlops: {
      'float32': 9,
      'float16': 18,
      'bfloat16': 18,
      'int8': 36,
      'q4': 54
    },
    type: 'GPU'
  },
  'RTX 2060': {
    name: 'NVIDIA RTX 2060 6GB',
    memoryGB: 6,
    localBandwidthGBps: 336,
    networkBandwidthGBps: 16,
    computeTFlops: {
      'float32': 6.5,
      'float16': 13,
      'bfloat16': 6.5,
      'int8': 26,
      'q4': 39
    },
    type: 'GPU'
  },
  'GTX 1650': {
    name: 'NVIDIA GTX 1650 4GB',
    memoryGB: 4,
    localBandwidthGBps: 128,
    networkBandwidthGBps: 16,
    computeTFlops: {
      'float32': 3,
      'float16': 6,
      'bfloat16': 3,
      'int8': 12,
      'q4': 18
    },
    type: 'GPU'
  },
  'GTX 1060': {
    name: 'NVIDIA GTX 1060 6GB',
    memoryGB: 6,
    localBandwidthGBps: 192,
    networkBandwidthGBps: 16,
    computeTFlops: {
      'float32': 4.4,
      'float16': 8.8,
      'bfloat16': 4.4,
      'int8': 17.6,
      'q4': 26
    },
    type: 'GPU'
  },
  'GT 730': {
    name: 'NVIDIA GT 730 2GB',
    memoryGB: 2,
    localBandwidthGBps: 40,
    networkBandwidthGBps: 5,
    computeTFlops: {
      'float32': 0.3,
      'float16': 0.6,
      'bfloat16': 0.3,
      'int8': 1.2,
      'q4': 1.8
    },
    type: 'GPU'
  },
  
  // AMD GPUs and CPUs
  'AMD MI300X': {
    name: 'AMD MI300X',
    memoryGB: 192,
    localBandwidthGBps: 5200,
    networkBandwidthGBps: 400 / 8,
    computeTFlops: {
      'float32': 380,
      'float16': 760,
      'bfloat16': 760,
      'int8': 1520,
      'q4': 2280
    },
    type: 'GPU'
  },
  'Threadripper Pro 7995WX': {
    name: 'AMD Threadripper Pro 7995WX',
    memoryGB: 1024,
    localBandwidthGBps: 300,
    networkBandwidthGBps: 100 / 8,
    computeTFlops: {
      'float32': 8,
      'float16': 16,
      'bfloat16': 16,
      'int8': 32,
      'q4': 48
    },
    type: 'CPU'
  },
  'AMD EPYC CPU (High-End)': {
    name: 'AMD EPYC CPU (High-End)',
    memoryGB: 256,
    localBandwidthGBps: 90,
    networkBandwidthGBps: 25/8,
    computeTFlops: {
      'float32': 2.5,
      'bfloat16': 5,
      'float16': 5,
      'int8': 10,
      'q4': 15
    },
    type: 'CPU'
  },
  'RX 7600': {
    name: 'AMD RX 7600 8GB',
    memoryGB: 8,
    localBandwidthGBps: 288,
    networkBandwidthGBps: 16,
    computeTFlops: {
      'float32': 11,
      'float16': 22,
      'bfloat16': 11,
      'int8': 44,
      'q4': 66
    },
    type: 'GPU'
  },
  'RX 6600': {
    name: 'AMD RX 6600 8GB',
    memoryGB: 8,
    localBandwidthGBps: 224,
    networkBandwidthGBps: 16,
    computeTFlops: {
      'float32': 9.8,
      'float16': 19.6,
      'bfloat16': 9.8,
      'int8': 39.2,
      'q4': 59
    },
    type: 'GPU'
  },
  'RX 580': {
    name: 'AMD RX 580 8GB',
    memoryGB: 8,
    localBandwidthGBps: 256,
    networkBandwidthGBps: 16,
    computeTFlops: {
      'float32': 6.2,
      'float16': 12.4,
      'bfloat16': 6.2,
      'int8': 24.8,
      'q4': 37
    },
    type: 'GPU'
  },
  'AMD Ryzen Integrated Graphics': {
    name: 'AMD Ryzen Integrated Graphics',
    memoryGB: 16,
    localBandwidthGBps: 50,
    networkBandwidthGBps: 2.5 / 8.0,
    computeTFlops: {
      'float32': 0.5,
      'bfloat16': 1.0,
      'float16': 1.0,
      'int8': 2.0,
      'q4': 3.0
    },
    type: 'Integrated GPU'
  },
  
  // Apple
  'Mac M3 Ultra (512)': {
    name: 'Mac M3 Ultra (512GB)',
    memoryGB: 512,
    localBandwidthGBps: 819,
    networkBandwidthGBps: 40/8,
    computeTFlops: {
      'float32': 35,
      'bfloat16': 70,
      'float16': 70,
      'int8': 140,
      'q4': 210
    },
    type: 'CPU/Integrated GPU'
  },
  'Mac M2 Ultra (192GB)': {
    name: 'Mac M2 Ultra (192GB)',
    memoryGB: 192,
    localBandwidthGBps: 800,
    networkBandwidthGBps: 40/8,
    computeTFlops: {
      'float32': 16,
      'bfloat16': 32,
      'float16': 32,
      'int8': 64,
      'q4': 96
    },
    type: 'CPU/Integrated GPU'
  },
  'Mac M4 Max (128)': {
    name: 'Mac M4 Max (128)',
    memoryGB: 128,
    localBandwidthGBps: 546,
    networkBandwidthGBps: 40/8,
    computeTFlops: {
      'float32': 18,
      'bfloat16': 35,
      'float16': 35,
      'int8': 70,
      'q4': 105
    },
    type: 'CPU/Integrated GPU'
  },
  'Mac Mini M2 (10G Ethernet)': {
    name: 'Mac Mini M2 (10G)',
    memoryGB: 16,
    localBandwidthGBps: 68,
    networkBandwidthGBps: 10/8,
    computeTFlops: {
      'float32': 2,
      'bfloat16': 4,
      'float16': 4,
      'int8': 8,
      'q4': 12
    },
    type: 'CPU/Integrated GPU'
  },
  
  // Intel
  'Intel Gaudi3': {
    name: 'Intel Gaudi3',
    memoryGB: 128,
    localBandwidthGBps: 3600,
    networkBandwidthGBps: 400 / 8,
    computeTFlops: {
      'float32': 320,
      'float16': 640,
      'bfloat16': 640,
      'int8': 1280,
      'q4': 1920
    },
    type: 'AI Accelerator'
  },
  'Intel Xeon CPU (High-End)': {
    name: 'Intel Xeon CPU (High-End)',
    memoryGB: 256,
    localBandwidthGBps: 80,
    networkBandwidthGBps: 25/8,
    computeTFlops: {
      'float32': 2,
      'bfloat16': 4,
      'float16': 4,
      'int8': 8,
      'q4': 12
    },
    type: 'CPU'
  },
  'Arc A770': {
    name: 'Intel Arc A770 16GB',
    memoryGB: 16,
    localBandwidthGBps: 560,
    networkBandwidthGBps: 16,
    computeTFlops: {
      'float32': 8.5,
      'float16': 17,
      'bfloat16': 17,
      'int8': 34,
      'q4': 51
    },
    type: 'GPU'
  },
  'Arc A380': {
    name: 'Intel Arc A380 6GB',
    memoryGB: 6,
    localBandwidthGBps: 192,
    networkBandwidthGBps: 8,
    computeTFlops: {
      'float32': 3.2,
      'float16': 6.4,
      'bfloat16': 6.4,
      'int8': 12.8,
      'q4': 19.2
    },
    type: 'GPU'
  },
  
  // Google
  'Google TPU v5p': {
    name: 'Google TPU v5p',
    memoryGB: 256,
    localBandwidthGBps: 3200,
    networkBandwidthGBps: 400 / 8,
    computeTFlops: {
      'float32': 450,
      'float16': 900,
      'bfloat16': 900,
      'int8': 1800,
      'q4': 2700
    },
    type: 'AI Accelerator'
  },
  
  // Cerebras
  'Cerebras WSE-3': {
    name: 'Cerebras WSE-3',
    memoryGB: 40000,
    localBandwidthGBps: 20000,
    networkBandwidthGBps: 800 / 8,
    computeTFlops: {
      'float32': 2400,
      'float16': 4800,
      'bfloat16': 4800,
      'int8': 9600,
      'q4': 14400
    },
    type: 'Wafer-Scale AI'
  },
  
  // AWS
  'AWS Inferentia2': {
    name: 'AWS Inferentia2',
    memoryGB: 32,
    localBandwidthGBps: 1000,
    networkBandwidthGBps: 100 / 8,
    computeTFlops: {
      'float32': 180,
      'float16': 360,
      'bfloat16': 360, 
      'int8': 720,
      'q4': 1080
    },
    type: 'AI Accelerator'
  },
  
  // Groq
  'Groq LPU-1': {
    name: 'Groq LPU-1',
    memoryGB: 80,
    localBandwidthGBps: 2500,
    networkBandwidthGBps: 200 / 8,
    computeTFlops: {
      'float32': 300,
      'float16': 600,
      'bfloat16': 600,
      'int8': 1200,
      'q4': 1800
    },
    type: 'AI Accelerator'
  },
  
  // NVMe/Storage Solutions
  'NVMe 4xRAID 5090 (Gen5)': {
    name: 'NVMe 4xRAID GPU (Gen5)',
    memoryGB: 8000,
    localBandwidthGBps: 32,
    networkBandwidthGBps: 40 / 8,
    computeTFlops: {
      'float32': 105,
      'float16': 210,
      'int8': 420,
      'q4': 630
    },
    type: 'GPU/NVMe'
  },
  'NVMe CPU (Gen5)': {
    name: 'NVMe CPU (Gen5)',
    memoryGB: 2000,
    localBandwidthGBps: 14,
    networkBandwidthGBps: 40 / 8,
    computeTFlops: {
      'float32': 2,
      'float16': 4,
      'int8': 8,
      'q4': 12
    },
    type: 'CPU/NVMe'
  },
  
  // Other devices
  'Rockchip 3588': {
    name: 'RK3588',
    memoryGB: 32,
    localBandwidthGBps: 38.4,
    networkBandwidthGBps: 2.5/8,
    computeTFlops: {
      'float16': 0.9,
      'int8': 1.8,
      'q4': 6
    },
    type: 'SBC'
  },
  'Raspberry Pi 5 (5G Ethernet)': {
    name: 'Raspberry Pi 5 (5G)',
    memoryGB: 8,
    localBandwidthGBps: 34,
    networkBandwidthGBps: 5 / 8.0,
    computeTFlops: {
      'float32': 0.1,
      'bfloat16': 0.2,
      'float16': 0.2,
      'int8': 0.4,
      'q4': 0.6
    },
    type: 'CPU/Integrated GPU'
  },
  'Desktop PC (2.5G Ethernet)': {
    name: 'Desktop PC (2.5G)',
    memoryGB: 32,
    localBandwidthGBps: 50,
    networkBandwidthGBps: 2.5 / 8.0,
    computeTFlops: {
      'float32': 1,
      'float16': 2,
      'int8': 4,
      'q4': 6
    },
    type: 'CPU/Integrated GPU'
  },
  
  // Custom
  'Custom': {
    name: 'Custom Device',
    memoryGB: 192,
    localBandwidthGBps: 50,
    networkBandwidthGBps: 2.5 / 8,
    computeTFlops: {
      'float32': 2,
      'float16': 4,
      'int8': 8,
      'q4': 12
    },
    type: 'Custom'
  }
};
        let devices = [{
            id: 1,
            name: 'Device 1',
            template: 'RTX 5090',
            ...DEVICE_TEMPLATES["RTX 5090"]
        }];
	    
        let utilizationChart = null;
        function getModelConfig() {
            return {
                modelPreset: document.getElementById('modelPreset').value,
                quantizationType: document.getElementById('quantizationType').value,
                totalParamsB: parseFloat(document.getElementById('totalParamsB').value),
                batchSize: parseFloat(document.getElementById('batchSize').value),
                seqLength: parseFloat(document.getElementById('seqLength').value),
                hiddenSize: parseFloat(document.getElementById('hiddenSize').value),
                numLayers: parseFloat(document.getElementById('numLayers').value),
                numHeads: parseFloat(document.getElementById('numHeads').value),
                dtype: document.getElementById('dtype').value,
                parallelismStrategy: document.getElementById('parallelismStrategy').value
            };
        }
	function calculateMemoryBreakdown(modelConfig, dtypeSize, deviceCount, isPipeline, deviceIndex ) {
		const paramsMemory = modelConfig.totalParamsB * 1e9 * dtypeSize;
		const kvCacheSizePerLayer = 2 * modelConfig.batchSize * modelConfig.seqLength * 
			(modelConfig.hiddenSize / modelConfig.numHeads) * 
			modelConfig.numHeads * dtypeSize;
		const kvCacheMemory = kvCacheSizePerLayer * modelConfig.numLayers;
		const activationSizePerLayer = modelConfig.batchSize * modelConfig.seqLength * 
			modelConfig.hiddenSize * dtypeSize;
		const activationMemory = activationSizePerLayer * modelConfig.numLayers;
		const attentionMemory = modelConfig.batchSize * (modelConfig.seqLength ** 2) * 
			modelConfig.numHeads * dtypeSize;

		// Calculate total available memory across all devices
		const totalSystemMemory = devices.reduce((sum, device) => sum + device.memoryGB * 1e9, 0);
		
		// Get this device's memory capacity
		const deviceMemory = devices[deviceIndex].memoryGB * 1e9;
		
		// Calculate proportion of total memory for this device
		const memoryProportion = deviceMemory / totalSystemMemory;

		// Adjust memory allocation based on device's proportion of total memory
		const adjustedParamsMemory = isPipeline ? 
			paramsMemory * memoryProportion : // Pipeline: divide based on memory proportion
			paramsMemory; // Tensor: replicate most params
			
		const adjustedKVCacheMemory = kvCacheMemory * memoryProportion;
		const adjustedActivationMemory = activationMemory * memoryProportion;
		const adjustedAttentionMemory = attentionMemory * memoryProportion;

		return {
			paramsMemory: adjustedParamsMemory,
			kvCacheMemory: adjustedKVCacheMemory,
			activationMemory: adjustedActivationMemory,
			attentionMemory: adjustedAttentionMemory,
			total: adjustedParamsMemory + adjustedKVCacheMemory + 
				   adjustedActivationMemory + adjustedAttentionMemory
		};
	}
	
	function calculateNetworkTraffic(modelConfig, dtypeSize, deviceCount, isPipeline) {
		if (deviceCount <= 1) return 0;

		const batchSize = modelConfig.batchSize;
		const seqLength = modelConfig.seqLength;
		const hiddenSize = modelConfig.hiddenSize;
		
		if (isPipeline) {
			// Pipeline parallelism: Forward and backward activation passing
			const activationSize = batchSize * seqLength * hiddenSize * dtypeSize;
			// Each layer boundary requires passing activations forward and gradients back
			return activationSize * 2 * (deviceCount - 1);
		} else {
			// Tensor parallelism: All-reduce for gradients and activations
			const gradientSize = modelConfig.totalParamsB * 1e9 * dtypeSize / deviceCount;
			const activationSize = batchSize * seqLength * hiddenSize * dtypeSize;
			// All-reduce communication pattern: (n-1)/n * data_size * 2
			return (deviceCount - 1) * (gradientSize + activationSize) * 2 / deviceCount;
		}
	}

        // Improved FLOPs calculation (more accurate for forward and backward pass)
        function calculateTransformerFlops(modelConfig) {
            const { batchSize, seqLength, hiddenSize, numLayers, numHeads } = modelConfig;

            // Forward pass FLOPs for one layer
            let forwardFlops = 0;

            // Self-Attention
            forwardFlops += 3 * (batchSize * seqLength * hiddenSize * hiddenSize); // Q, K, V projections
            forwardFlops += batchSize * numHeads * seqLength * seqLength * (hiddenSize / numHeads); // Attention scores
            forwardFlops += batchSize * numHeads * seqLength * (hiddenSize / numHeads) * (hiddenSize / numHeads); // Weighted sum
            forwardFlops += batchSize * seqLength * hiddenSize * hiddenSize; // Output projection

            // Feed-Forward Network
            forwardFlops += batchSize * seqLength * hiddenSize * (4 * hiddenSize); // First layer
            forwardFlops += batchSize * seqLength * (4 * hiddenSize) * hiddenSize; // Second layer

            // Multiply by number of layers and then by 3 for forward + backward pass
            return forwardFlops * numLayers * 3;
        }

        function calculateDecodeFlops(modelConfig) {
            const { batchSize, seqLength, hiddenSize, numLayers, numHeads } = modelConfig;

            // Decode FLOPs are dominated by KV cache interactions and are roughly:
            let decodeFlops = 0;

            // KV Cache interaction in self-attention (per layer)
            decodeFlops += 2 * batchSize * seqLength * hiddenSize * hiddenSize; 

            // Feed-Forward Network (remains similar to prefill per token)
            decodeFlops += batchSize * hiddenSize * (4 * hiddenSize); // First layer
            decodeFlops += batchSize * (4 * hiddenSize) * hiddenSize; // Second layer

            return decodeFlops * numLayers; 
        }
	    
	// Load devices from localStorage
	function loadDevices() {
	    const savedDevices = localStorage.getItem('savedDevices');
	    if (savedDevices) {
	        try {
	            devices = JSON.parse(savedDevices);
	            updateDeviceDisplay();
	            updateSystemAnalysis();
	        } catch (e) {
	            console.error('Error loading saved devices:', e);
	        }
	    }
	}
	
	// Save devices to localStorage
	function saveDevices() {
	    localStorage.setItem('savedDevices', JSON.stringify(devices));
	}
	
	// Add a new empty device with a default template
	function addDevice() {
	    const newId = devices.length > 0 ? Math.max(...devices.map(d => d.id)) + 1 : 1;
	    const defaultTemplate = 'RTX 5090';
	    const newDevice = {
	        id: newId,
	        name: `Device ${newId}`,
	        template: defaultTemplate,
	        ...DEVICE_TEMPLATES[defaultTemplate]
	    };
	    devices.push(newDevice);
	    updateDeviceDisplay();
	    updateSystemAnalysis();
	    saveDevices();
	}
	
	// Clone an existing device
	function cloneDevice(id) {
	    const sourceDevice = devices.find(d => d.id === id);
	    if (!sourceDevice) return;
	    
	    const newId = Math.max(...devices.map(d => d.id)) + 1;
	    const newDevice = {
	        ...JSON.parse(JSON.stringify(sourceDevice)), // Deep clone
	        id: newId,
	        name: `${sourceDevice.name} (Clone)`
	    };
	    
	    devices.push(newDevice);
	    updateDeviceDisplay();
	    updateSystemAnalysis();
	    saveDevices();
	}
	
	// Remove a device
	function removeDevice(id) {
	    if (devices.length > 1) {
	        devices = devices.filter(d => d.id !== id);
	        updateDeviceDisplay();
	        updateSystemAnalysis();
	        saveDevices();
	    }
	}
	
	function updateDevice(id, field, value) {
	    devices = devices.map(d => {
	        if (d.id !== id) return d;
	        
	        let updatedDevice = { ...d };
	        
	        if (field === 'template') {
	            if (value !== 'Custom') {
	                // Update entire device with template
	                updatedDevice = { 
	                    ...updatedDevice, 
	                    ...DEVICE_TEMPLATES[value],
	                    template: value, // Keep the template name
	                    name: updatedDevice.name // Keep original name
	                };
	            } else {
	                updatedDevice.template = 'Custom';
	            }
	        } else if (field === 'computeTFlops') {
	            // For custom devices, use the entered value as base and scale for other precisions
	            const currentQuant = document.getElementById('quantizationType').value;
	            const baseValue = value / {
	                'float32': 1,
	                'bfloat16': 2,
	                'float16': 2,
	                'int8': 4,
	                'q4': 6
	            }[currentQuant];
	
	            updatedDevice.computeTFlops = {
	                'float32': baseValue,
	                'bfloat16': baseValue * 2,
	                'float16': baseValue * 2,
	                'int8': baseValue * 4,
	                'q4': baseValue * 6
	            };
	            
	            // Automatically switch to custom template when modifying values
	            if (updatedDevice.template !== 'Custom') {
	                updatedDevice.template = 'Custom';
	            }
	        } else {
	            updatedDevice[field] = value;
	            
	            // Automatically switch to custom template when modifying specs
	            if (field !== 'name' && field !== 'template' && updatedDevice.template !== 'Custom') {
	                updatedDevice.template = 'Custom';
	            }
	        }
	        
	        return updatedDevice;
	    });
	    
	    updateDeviceDisplay();
	    updateSystemAnalysis();
	    saveDevices();
	}
	
	// Device library management
	function saveToLibrary(id) {
	    const device = devices.find(d => d.id === id);
	    if (!device) return;
	    
	    // Get existing library
	    let deviceLibrary = [];
	    try {
	        const savedLibrary = localStorage.getItem('deviceLibrary');
	        if (savedLibrary) {
	            deviceLibrary = JSON.parse(savedLibrary);
	        }
	    } catch (e) {
	        console.error('Error loading device library:', e);
	    }
	    
	    // Create a copy to save
	    const deviceToSave = {
	        ...JSON.parse(JSON.stringify(device)),
	        template: 'Custom', // Force as custom when saved
	        id: Date.now() // Use timestamp as unique ID in library
	    };
	    
	    // Add to library
	    deviceLibrary.push(deviceToSave);
	    localStorage.setItem('deviceLibrary', JSON.stringify(deviceLibrary));
	    
	    alert(`Device "${device.name}" saved to library!`);
	    updateDeviceDisplay(); // Refresh to show updated library
	}
        function calculateMetrics() {
			const modelConfig = getModelConfig();
			const dtypeSize = DTYPE_SIZES[modelConfig.quantizationType];
			const isPipeline = modelConfig.parallelismStrategy === 'pipeline';
			const deviceCount = devices.length;

			return devices.map((device, deviceIndex) => {
				// Calculate per-device memory and network requirements
				const memoryBreakdown = calculateMemoryBreakdown(modelConfig, dtypeSize, deviceCount, isPipeline, deviceIndex);
				const networkTraffic = calculateNetworkTraffic(modelConfig, dtypeSize, deviceCount, isPipeline);
				
				const quantSpeedFactor = {
					'float32': 1.0,
					'bfloat16': 2.0,
					'float16': 2.0,
					'int8': 2.5,
					'q4': 3.0
				}[modelConfig.quantizationType] || 1.0;

				const totalPrefillFlops = calculateTransformerFlops(modelConfig) / (deviceCount * quantSpeedFactor);
				const theoreticalPrefillComputeTime = totalPrefillFlops / (device.computeTFlops[modelConfig.quantizationType] * 1e12);


				// Network time calculation
				const networkTime = networkTraffic / (device.networkBandwidthGBps * 1e9);
				
				// Memory traffic calculation adjusted for distributed setup
				const memoryTrafficScale = modelConfig.quantizationType === 'q4' ? 1.2 : 1.0; // Q4 has some overhead
				const totalPrefillMemoryTraffic = memoryTrafficScale * (
					memoryBreakdown.paramsMemory + 
					(2 * memoryBreakdown.kvCacheMemory) +
					(3 * memoryBreakdown.activationMemory) +
					(2 * memoryBreakdown.attentionMemory)
				);

				const prefillBandwidthLimitedTime = totalPrefillMemoryTraffic / (device.localBandwidthGBps * 1e9);

				// Include network time in actual execution time
				const overheadFactorPrefill = 1.05;
				const actualPrefillTime = Math.max(
					theoreticalPrefillComputeTime,
					prefillBandwidthLimitedTime,
					networkTime
				) * overheadFactorPrefill;

				// Calculate utilizations
				const prefillComputeUtilization = (theoreticalPrefillComputeTime / actualPrefillTime) * 100;
				const prefillLocalBandwidthUtilization = (prefillBandwidthLimitedTime / actualPrefillTime) * 100;
				const networkBandwidthUtilization = (networkTime / actualPrefillTime) * 100;
				const memoryUtilization = (memoryBreakdown.total / (device.memoryGB * 1e9)) * 100;

				// Calculate bottleneck factor
				const bottleneckFactor = Math.max(
					1,
					prefillComputeUtilization / 100,
					memoryUtilization / 100,
					prefillLocalBandwidthUtilization / 100,
					networkBandwidthUtilization / 100
				);

				// Calculate token throughput
				const prefillTokensPerSecond = modelConfig.batchSize * modelConfig.seqLength / actualPrefillTime;

				// Decode calculations remain similar but scaled by device count
				const decodeFlops = calculateDecodeFlops(modelConfig) / deviceCount;
				const theoreticalDecodeTime = decodeFlops / (device.computeTFlops[modelConfig.quantizationType] * 1e12);

				const decodeMemoryTrafficPerToken = (
					memoryBreakdown.paramsMemory + 
					(2 * modelConfig.seqLength * (modelConfig.hiddenSize / modelConfig.numHeads) * 
					 modelConfig.numHeads * dtypeSize) * modelConfig.numLayers / deviceCount + 
					(4 * modelConfig.hiddenSize * dtypeSize) * modelConfig.numLayers / deviceCount
				) / modelConfig.seqLength;

				const decodeBandwidthLimitedTime = decodeMemoryTrafficPerToken / (device.localBandwidthGBps * 1e9);
				const overheadFactorDecode = 1.5;
				const actualDecodeTime = Math.max(theoreticalDecodeTime, decodeBandwidthLimitedTime) * 
					overheadFactorDecode;

				return {
					name: device.name,
					memoryUtilization,
					localBandwidthUtilization: prefillLocalBandwidthUtilization,
					networkBandwidthUtilization,
					computeUtilization: prefillComputeUtilization,
					rawMemoryUtilization: memoryUtilization,
					rawLocalBandwidthUtilization: prefillLocalBandwidthUtilization,
					rawNetworkBandwidthUtilization: networkBandwidthUtilization,
					rawComputeUtilization: prefillComputeUtilization,
					bottleneckFactor,
					isBottleneck: bottleneckFactor > 1,
					prefillTokensPerSecond,
					decodeTokensPerSecond: modelConfig.batchSize / actualDecodeTime,
					decodeComputeUtilization: (theoreticalDecodeTime / actualDecodeTime) * 100,
					decodeLocalBandwidthUtilization: (decodeBandwidthLimitedTime / actualDecodeTime) * 100,
					decodeBottleneckFactor: Math.max(
						theoreticalDecodeTime / actualDecodeTime,
						decodeBandwidthLimitedTime / actualDecodeTime
					)
				};
			});
		}

        function updateSystemAnalysis() {
            const metrics = calculateMetrics();
            console.log(metrics);
            const analysisContainer = document.getElementById('systemAnalysis');
            let systemAnalysisHtml = '';
            metrics.forEach(m => {
                systemAnalysisHtml += `
                    <div style="margin-bottom: 1rem;">
                        <h3>${m.name}</h3>
                        <div class="device-grid" style="font-size: 0.875rem;">
                            <div>Memory Usage: ${m.memoryUtilization.toFixed(1)}%</div>
                            <div>Compute Usage: ${m.computeUtilization.toFixed(1)}%</div>
                            <div>Local BW Usage: ${m.localBandwidthUtilization.toFixed(1)}%</div>
                            <div>Network BW Usage: ${m.networkBandwidthUtilization.toFixed(1)}%</div>
                            <div><strong>Prefill Token Rate (approx.):</strong> ${m.prefillTokensPerSecond.toFixed(2)} tokens/second</div>
                            <div><strong>Decode Token Rate (approx.):</strong> ${m.decodeTokensPerSecond.toFixed(2)} tokens/second</div>
                        </div>
                `;
                // Determine bottleneck for reporting
                let bottleneckType = "None";
                let bottleneckValue = 1;
                if (m.isBottleneck) {
                    if (m.computeUtilization > bottleneckValue) {
                        bottleneckType = "Compute";
                        bottleneckValue = m.computeUtilization;
                    }
                    if (m.memoryUtilization > bottleneckValue) {
                        bottleneckType = "Memory";
                        bottleneckValue = m.memoryUtilization;
                    }
                    if (m.localBandwidthUtilization > bottleneckValue) {
                        bottleneckType = "Local Bandwidth";
                        bottleneckValue = m.localBandwidthUtilization;
                    }
                    if (m.networkBandwidthUtilization > bottleneckValue) {
                        bottleneckType = "Network Bandwidth";
                        bottleneckValue = m.networkBandwidthUtilization;
                    }
                    systemAnalysisHtml += `
                        <div style="color: #ff4444; font-size: 0.875rem; margin-top: 0.5rem;">
                            Prefill performance limited by <strong><span class="math-inline">${bottleneckType}</strong\> constraints (</span>${m.bottleneckFactor.toFixed(1)}x slower)
                        </div>
                    `;
                }
                // Decode bottleneck (simplified for reporting)
                if (m.decodeBottleneckFactor > 1) {
                    let decodeBottleneckType = "None";
                    if (m.decodeComputeUtilization > m.decodeLocalBandwidthUtilization) {
                        decodeBottleneckType = "Compute";
                    } else {
                        decodeBottleneckType = "Local Bandwidth";
                    }
                    systemAnalysisHtml += `
                        <div style="color: #ff4444; font-size: 0.875rem; margin-top: 0.5rem;">
                            Decode performance limited by <strong><span class="math-inline">\{decodeBottleneckType\}</strong\> constraints \(</span>{m.decodeBottleneckFactor.toFixed(1)}x slower)
                        </div>
                    `;
                }
                systemAnalysisHtml += `</div>`;
            });
            analysisContainer.innerHTML = systemAnalysisHtml;
            updateAlerts(metrics);
            updateChart(metrics);
        }
	    
	function updateDeviceDisplay() {
	    const currentQuant = document.getElementById('quantizationType').value;
	    const devicesContainer = document.getElementById('devices');
	    
	    // Get saved device library
	    let deviceLibrary = [];
	    try {
	        const savedLibrary = localStorage.getItem('deviceLibrary');
	        if (savedLibrary) {
	            deviceLibrary = JSON.parse(savedLibrary);
	        }
	    } catch (e) {
	        console.error('Error loading device library:', e);
	    }
	    
	    // Create custom library options
	    const libraryOptions = deviceLibrary.map(device => 
	        `<option value="lib_${device.id}">${device.name}</option>`
	    ).join('');
	    
	    devicesContainer.innerHTML = devices.map(device => `
	        <div class="device ${device.template === 'Custom' || device.isEdited ? 'custom-device' : ''}">
	            ${device.template === 'Custom' || device.isEdited ? '<div class="custom-badge">Custom</div>' : ''}
	            <div style="display: flex; justify-content: space-between; margin-bottom: 0.5rem;">
	                <input class="input" title="Give this device a name" style="width: auto; flex-grow: 1; margin-right: 0.5rem;" value="${device.name}"
	                       onchange="updateDevice(${device.id}, 'name', this.value)">
	                <div class="device-actions">
	                    <button class="button" 
	                            onclick="cloneDevice(${device.id})"
	                            title="Clone this device">
	                        Clone
	                    </button>
	                    <button class="button" 
	                            onclick="saveToLibrary(${device.id})"
	                            title="Save to library">
	                        Save
	                    </button>
	                    <button class="button button-destructive"
	                            onclick="removeDevice(${device.id})"
	                            ${devices.length === 1 ? 'disabled' : ''}
	                            title="Remove this device">
	                        Remove
	                    </button>
	                </div>
	            </div>
	            <select class="input" onchange="handleDeviceTemplateChange(${device.id}, this)">
	                <option value="Custom" ${device.template === 'Custom' ? 'selected' : ''}>
	                    Custom Device
	                </option>
	                <optgroup label="Preset Library">
	                    ${Object.keys(DEVICE_TEMPLATES)
	                        .filter(key => key !== 'Custom')
	                        .map(template => `
	                            <option value="${template}" ${device.template === template && !device.isEdited ? 'selected' : ''}>
	                                ${DEVICE_TEMPLATES[template].name}
	                            </option>
	                        `).join('')}
	                </optgroup>
	                ${deviceLibrary.length > 0 ? 
	                    `<optgroup label="My Saved Devices">
	                        ${libraryOptions}
	                    </optgroup>` : ''}
	            </select>
	            <div class="device-grid">
	                <div>
	                    <label>Memory GB</label>
	                    <input type="number" class="input" value="${device.memoryGB}"
	                           onchange="updateDevice(${device.id}, 'memoryGB', parseFloat(this.value) || 0)"
	                           oninput="updateDevice(${device.id}, 'memoryGB', parseFloat(this.value) || 0)">
	                </div>
	                <div>
	                    <label>Local Bandwidth GBps</label>
	                    <input type="number" class="input" value="${device.localBandwidthGBps}"
	                           onchange="updateDevice(${device.id}, 'localBandwidthGBps', parseFloat(this.value) || 0)"
	                           oninput="updateDevice(${device.id}, 'localBandwidthGBps', parseFloat(this.value) || 0)">
	                </div>
	                <div>
	                    <label>Network Bandwidth GBps</label>
	                    <input type="number" class="input" value="${device.networkBandwidthGBps}"
	                           onchange="updateDevice(${device.id}, 'networkBandwidthGBps', parseFloat(this.value) || 0)"
	                           oninput="updateDevice(${device.id}, 'networkBandwidthGBps', parseFloat(this.value) || 0)">
	                </div>
	                <div>
	                    <label>Compute TFlops (${currentQuant})</label>
	                    <input type="number" class="input" value="${device.computeTFlops[currentQuant]}"
	                           onchange="updateDevice(${device.id}, 'computeTFlops', parseFloat(this.value) || 0)"
	                           oninput="updateDevice(${device.id}, 'computeTFlops', parseFloat(this.value) || 0)">
	                </div>
	            </div>
	        </div>
	    `).join('');
	    
	    // Add the "Add New Device" button at the bottom
	    devicesContainer.innerHTML += `
	        <div style="display: flex; justify-content: center; margin-top: 1rem;">
	            <button class="button" onclick="addDevice()" style="width: 100%;">
	                + Add New Device
	            </button>
	        </div>
	    `;
	}
        function updateAlerts(metrics) {
            const alertsContainer = document.getElementById('alerts');
            let alertsHtml = '';
            if (metrics.some(m => m.isBottleneck)) {
                alertsHtml += `
                    <div class="alert">
                        <div style="font-weight: 600; margin-bottom: 0.5rem;">
                            Configuration Issues:
                        </div>
                        ${metrics.filter(m => m.isBottleneck).map(m => `
                            <div style="margin-left: 1rem;">
                                • ${m.name}:
                                ${m.memoryUtilization > 100 ?
                    ` Requires ${(m.memoryUtilization / 100).toFixed(1)}x more memory` : ''}
                                ${m.localBandwidthUtilization > 100 ?
                    ` Requires ${(m.localBandwidthUtilization / 100).toFixed(1)}x more local bandwidth` : ''}
                                ${m.networkBandwidthUtilization > 100 && getModelConfig().parallelismStrategy === 'pipeline' ?
                    ` Requires ${(m.networkBandwidthUtilization / 100).toFixed(1)}x more network bandwidth` : ''}
                                ${m.computeUtilization > 100 ?
                    ` Requires ${(m.computeUtilization / 100).toFixed(1)}x more compute` : ''}
                            </div>
                        `).join('')}
                    </div>
                `;
            }
            alertsContainer.innerHTML = alertsHtml;
        }
	    
        function updateChart(metrics) {
            const ctx = document.getElementById('utilizationChart').getContext('2d');
            const chartData = {
                labels: metrics.map(m => m.name),
                datasets: [
                    {
                        label: 'Memory',
                        data: metrics.map(m => m.memoryUtilization),
                        backgroundColor: '#8884d8'
                    },
                    {
                        label: 'Local Bandwidth',
                        data: metrics.map(m => m.localBandwidthUtilization),
                        backgroundColor: '#82ca9d'
                    },
                    {
                        label: 'Network Bandwidth',
                        data: metrics.map(m => m.networkBandwidthUtilization),
                        backgroundColor: '#ffc658'
                    },
                    {
                        label: 'Compute',
                        data: metrics.map(m => m.computeUtilization),
                        backgroundColor: '#ff7300'
                    }
                ]
            };
            if (utilizationChart) {
                utilizationChart.destroy();
            }
            utilizationChart = new Chart(ctx, {
                type: 'bar',
                data: chartData,
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    scales: {
                        y: {
                            beginAtZero: true,
                            max: 120,
                            title: {
                                display: true,
                                text: 'Utilization %'
                            }
                        }
                    },
                    plugins: {
                        tooltip: {
                            callbacks: {
                                label: function (context) {
                                    const index = context.dataIndex;
                                    const metric = metrics[index];
                                    const datasetLabel = context.dataset.label;
                                    let actualValue, rawValue;
                                    switch (datasetLabel) {
                                        case 'Memory':
                                            actualValue = metric.memoryUtilization;
                                            rawValue = metric.rawMemoryUtilization;
                                            break;
                                        case 'Local Bandwidth':
                                            actualValue = metric.localBandwidthUtilization;
                                            rawValue = metric.rawLocalBandwidthUtilization;
                                            break;
                                        case 'Network Bandwidth':
                                            actualValue = metric.networkBandwidthUtilization;
                                            rawValue = metric.rawNetworkBandwidthUtilization;
                                            break;
                                        case 'Compute':
                                            actualValue = metric.computeUtilization;
                                            rawValue = metric.rawComputeUtilization;
                                            break;
                                    }
                                    if (rawValue !== actualValue) {
                                        return `${datasetLabel}: ${actualValue.toFixed(1)}% (theoretical max: ${rawValue.toFixed(1)}%)`;
                                    }
                                    return `${datasetLabel}: ${actualValue.toFixed(1)}%`;
                                }
                            }
                        }
                    }
                }
            });
        }
        function addDevice() {
            const lastDevice = devices[devices.length - 1];
            const newDevice = {
                id: devices.length + 1,
                name: `Device ${devices.length + 1}`,
                template: lastDevice.template,
                ...DEVICE_TEMPLATES[lastDevice.template === 'Custom' ? 'Custom' : lastDevice.template],
                memoryGB: lastDevice.memoryGB,
                localBandwidthGBps: lastDevice.localBandwidthGBps,
                networkBandwidthGBps: lastDevice.networkBandwidthGBps,
                computeTFlops: lastDevice.computeTFlops
            };
            devices.push(newDevice);
            updateDeviceDisplay();
            updateSystemAnalysis();
        }
        function removeDevice(id) {
            if (devices.length > 1) {
                devices = devices.filter(d => d.id !== id);
                updateDeviceDisplay();
                updateSystemAnalysis();
            }
        }
	    
	function updateDevice(id, field, value) {
	    const device = devices.find(d => d.id === id);
	    if (!device) return;
	    
	    // Check if the value is actually different before marking as edited
	    let valueChanged = false;
	    
	    if (field === 'computeTFlops') {
	        const currentQuant = document.getElementById('quantizationType').value;
	        valueChanged = device.computeTFlops[currentQuant] !== value;
	    } else if (field !== 'name' && field !== 'template') {
	        valueChanged = device[field] !== value;
	    }
	    
	    devices = devices.map(d => {
	        if (d.id !== id) return d;
	        
	        let updatedDevice = { ...d };
	        
	        if (field === 'template') {
	            if (value !== 'Custom') {
	                // Update entire device with template
	                updatedDevice = { 
	                    ...updatedDevice, 
	                    ...DEVICE_TEMPLATES[value],
	                    template: value, // Keep the template name
	                    name: DEVICE_TEMPLATES[value].name, // Use template name
	                    isEdited: false
	                };
	            } else {
	                updatedDevice.template = 'Custom';
	                updatedDevice.name = 'Custom Device';
	                updatedDevice.isEdited = true;
	            }
	        } else if (field === 'computeTFlops') {
	            // For custom devices, use the entered value as base and scale for other precisions
	            const currentQuant = document.getElementById('quantizationType').value;
	            const baseValue = value / {
	                'float32': 1,
	                'bfloat16': 2,
	                'float16': 2,
	                'int8': 4,
	                'q4': 6
	            }[currentQuant];
	
	            updatedDevice.computeTFlops = {
	                'float32': baseValue,
	                'bfloat16': baseValue * 2,
	                'float16': baseValue * 2,
	                'int8': baseValue * 4,
	                'q4': baseValue * 6
	            };
	            
	            // Mark as edited if value changed and not already custom
	            if (valueChanged && !updatedDevice.isEdited && updatedDevice.template !== 'Custom') {
	                updatedDevice.isEdited = true;
	                // Add "- Custom" to the name if not already there
	                if (!updatedDevice.name.includes('- Custom')) {
	                    updatedDevice.name = `${updatedDevice.name} - Custom`;
	                }
	            }
	        } else {
	            updatedDevice[field] = value;
	            
	            // Skip for name field updates or already edited devices
	            if (valueChanged && field !== 'name' && !updatedDevice.isEdited && updatedDevice.template !== 'Custom') {
	                updatedDevice.isEdited = true;
	                // Add "- Custom" to the name
	                if (!updatedDevice.name.includes('- Custom')) {
	                    updatedDevice.name = `${updatedDevice.name} - Custom`;
	                }
	            }
	        }
	        
	        return updatedDevice;
	    });
	    
	    updateDeviceDisplay();
	    updateSystemAnalysis();
	    saveDevices();
	}
	
	function updateModelConfigFromPreset() {
		const modelPresetId = document.getElementById('modelPreset').value;
		if (modelPresetId && MODEL_PRESETS[modelPresetId]) {
			const preset = MODEL_PRESETS[modelPresetId];
			for (const key in preset) {
				if (document.getElementById(key)) {
					document.getElementById(key).value = preset[key];
				}
			}
		} else if (modelPresetId === "") {
			// Reset to empty values if no preset selected
			const defaultKeys = ['totalParamsB', 'hiddenSize', 'numLayers', 'numHeads'];
			defaultKeys.forEach(key => {
				if (document.getElementById(key)) {
					document.getElementById(key).value = '';
				}
			});
		}
		updateSystemAnalysis();
	}


        document.getElementById('modelPreset').addEventListener('change', updateModelConfigFromPreset);
        document.getElementById('quantizationType').addEventListener('change', () => {
			// Update display for custom devices
			updateDeviceDisplay();
			updateSystemAnalysis();
		});
        document.querySelectorAll('#modelConfig input, #modelConfig select').forEach(input => {
            if (input.id !== 'modelPreset' && input.id !== 'quantizationType' && input.id !== 'dtype') {
                input.addEventListener('change', updateSystemAnalysis);
            }
        });
		updateModelConfigFromPreset();
        updateDeviceDisplay();
        updateSystemAnalysis();
		
		        const rawData = `Model	Quantization	Framework	Hardware	Batch Size	Sequence Length	Token Rate (Batch)	Token Rate (Single)	Source
Llama 3.1 8b	FP16		Groq				100 t/s	https://www.vellum.ai/llm-leaderboard
Llama 3.1 70b	FP16		Groq				40 t/s	https://www.vellum.ai/llm-leaderboard
Llama 3.1 405b	FP16		Groq				10 t/s	https://www.vellum.ai/llm-leaderboard
Claude 3 Opus					4096		25 t/s	https://www.vellum.ai/llm-leaderboard
GPT-4					8192		125 t/s	https://www.vellum.ai/llm-leaderboard
Claude 3.5 Sonnet						170.4 t/s		https://yourgpt.ai/tools/llm-comparison-and-leaderboard
llama3-8b			SambaNova's RDU (Reconfigurable Dataflow Unit) system with 8-chips		4096	430 t/s		https://blog.lancedb.com/tokens-per-second-is-not-all-you-need/
Mistral 7B	FP16	vLLM	A10G	1			30.9 t/s	https://lightning.ai/lightning-ai/studios/optimized-llm-inference-api-for-mistral-7b-using-vllm
Mistral 7B	FP16	vLLM	4 x A10G	1			64.5 t/s	https://lightning.ai/lightning-ai/studios/optimized-llm-inference-api-for-mistral-7b-using-vllm
Mistral 7B	AWQ 4-bit	vLLM	A10G	1			86.1 t/s	https://lightning.ai/lightning-ai/studios/optimized-llm-inference-api-for-mistral-7b-using-vllm
Mistral 7B	FP16			1	80x100		170 t/s	https://www.baseten.co/blog/benchmarking-fast-mistral-7b-inference/
Mistral-8x7B	Q8_0		RTX 4090				6.55 t/s	https://www.reddit.com/r/LocalLLaMA/comments/18jslmf/tokens_per_second_mistral_8x7b_performance/
Mistral-8x7B	Q5_K_M		RTX 4090				13.16 t/s	https://www.reddit.com/r/LocalLLaMA/comments/18jslmf/tokens_per_second_mistral_8x7b_performance/
Mistral-8x7B	Q4_K_M		RTX 4090				23.06 t/s	https://www.reddit.com/r/LocalLLaMA/comments/18jslmf/tokens_per_second_mistral_8x7b_performance/
Mistral-8x7B	Q8_0		AMD 7950X3D				3.95 t/s	https://www.reddit.com/r/LocalLLaMA/comments/18jslmf/tokens_per_second_mistral_8x7b_performance/
Mistral-8x7B	Q4_K_M		2 x RTX 3090				48.26 t/s	https://www.reddit.com/r/LocalLLaMA/comments/18jslmf/tokens_per_second_mistral_8x7b_performance/
Mistral 7B	Q4		Raspberry Pi 5				2 t/s	https://dmatora.github.io/LLM-inference-speed-benchmarks/
Mistral 7B	Q4		i7-7700HQ (CPU)				3 t/s	https://dmatora.github.io/LLM-inference-speed-benchmarks/
Mistral 7B	Q4		Apple M1 (CPU)				12 t/s	https://dmatora.github.io/LLM-inference-speed-benchmarks/
Mistral 7B	Q4		RTX 4060 Ti				44 t/s	https://dmatora.github.io/LLM-inference-speed-benchmarks/
Mistral 7B	Q4		Tesla P40				45 t/s	https://dmatora.github.io/LLM-inference-speed-benchmarks/
Mistral 7B	Q4		Apple M1 Max (CPU)				58 t/s	https://dmatora.github.io/LLM-inference-speed-benchmarks/
Mistral 7B	Q4		Nvidia RTX 3060				59 t/s	https://dmatora.github.io/LLM-inference-speed-benchmarks/
Mistral 7B	Q4		Apple M1 Ultra (CPU)				70 t/s	https://dmatora.github.io/LLM-inference-speed-benchmarks/
Mistral 7B	Q4		Nvidia RTX 4070				70 t/s	https://dmatora.github.io/LLM-inference-speed-benchmarks/
Mistral 7B	Q4		Nvidia RTX 3090				120 t/s	https://dmatora.github.io/LLM-inference-speed-benchmarks/
Mistral 7B	Q4		Nvidia RTX 4090				140 t/s	https://dmatora.github.io/LLM-inference-speed-benchmarks/
Mistral SM 3.1 24B	8bit		M3 Ultra				26.23 t/s	https://x.com/ivanfioravanti/status/1902375006228902041
Mistral SM 3.1 24B	8bit		M2 Ultra				27.16 t/s	https://x.com/ivanfioravanti/status/1902375006228902041
Mistral SM 3.1 24B	8bit		M4 Max				19.24 t/s	https://x.com/ivanfioravanti/status/1902375006228902041
Llama 2 70B	FP16		2 x Tesla P40				3 t/s	https://dmatora.github.io/LLM-inference-speed-benchmarks/
Llama 2 70B	Q4		Apple M1 Max (CPU)				6 t/s	https://dmatora.github.io/LLM-inference-speed-benchmarks/
CodeLlama 70B	Q5_K_M	llama.cpp	Apple M2 Ultra (CPU)				8.72 t/s	https://obrienlabs.medium.com/running-the-70b-llama-2-llm-locally-on-metal-via-llama-cpp-on-mac-studio-m2-ultra-32b3179e9cbe
Llama 2 7B	FP16	vLLM	NVIDIA H100 SXM	1	2048	1000 t/s		https://blog.ori.co/benchmarking-llama-3.1-8b-instruct-on-nvidia-h100-and-a100-chips-with-the-vllm-inferencing-engine
Llama 2 7B	FP16	vLLM	NVIDIA A100	1	2048	500 t/s		https://blog.ori.co/benchmarking-llama-3.1-8b-instruct-on-nvidia-h100-and-a100-chips-with-the-vllm-inferencing-engine
GPT-J 6B	FP8	TensorRT-LLM	NVIDIA H100	64	128	10,907 t/s		https://nvidia.github.io/TensorRT-LLM/blogs/H100vsA100.html
GPT-J 6B	FP16	TensorRT-LLM	NVIDIA A100	64	128	3,679 t/s		https://nvidia.github.io/TensorRT-LLM/blogs/H100vsA100.html
DeepSeek V3	INT8	Exo	2 x Mac M3 Ultra 512GB				11 t/s	https://x.com/alexocheema/status/1899735281781411907
DeepSeek V3	FP16		NVIDIA H800 x 2048					https://www.infoq.com/news/2025/01/deepseek-v3-llm/`;

        const data = rawData.split('\n')
            .filter(line => line.trim())
            .map(line => {
                const [model, quantization, framework, hardware, batchSize, seqLength, tokenRateBatch, tokenRateSingle, source] = line.split('\t');
                return {
                    model, quantization, framework, hardware, batchSize, 
                    seqLength, tokenRateBatch, tokenRateSingle, source
                };
            });

        // Function to render the table
        const renderTable = (data) => {
            const tbody = document.querySelector('#llmTable tbody');
            tbody.innerHTML = '';
            
            data.forEach(row => {
                const tr = document.createElement('tr');
                Object.values(row).forEach(value => {
                    const td = document.createElement('td');
                    td.textContent = value || '';
                    if (value && value.startsWith('http')) {
                        const a = document.createElement('a');
                        a.href = value;
                        a.textContent = 'Link';
                        a.target = '_blank';
                        td.textContent = '';
                        td.appendChild(a);
                    }
                    tr.appendChild(td);
                });
                tbody.appendChild(tr);
            });
        };

        // Sorting function
        const sortTable = (column, direction = 'asc') => {
            const sortedData = [...data].sort((a, b) => {
                let aVal = a[column] || '';
                let bVal = b[column] || '';
                
                // Extract numerical values from strings like "100 t/s"
                if (aVal.includes('t/s')) {
                    aVal = parseFloat(aVal.replace(' t/s', '').replace(',', ''));
                }
                if (bVal.includes('t/s')) {
                    bVal = parseFloat(bVal.replace(' t/s', '').replace(',', ''));
                }
                
                // Convert to numbers if possible
                if (!isNaN(aVal) && !isNaN(bVal)) {
                    aVal = parseFloat(aVal);
                    bVal = parseFloat(bVal);
                }
                
                if (direction === 'asc') {
                    return aVal > bVal ? 1 : -1;
                } else {
                    return aVal < bVal ? 1 : -1;
                }
            });
            
            renderTable(sortedData);
        };

	function handleDeviceTemplateChange(id, selectElement) {
	    const value = selectElement.value;
	    
	    // Check if this is a library device
	    if (value.startsWith('lib_')) {
	        const libraryId = value.replace('lib_', '');
	        
	        try {
	            const savedLibrary = localStorage.getItem('deviceLibrary');
	            if (savedLibrary) {
	                const deviceLibrary = JSON.parse(savedLibrary);
	                const libraryDevice = deviceLibrary.find(d => d.id.toString() === libraryId);
	                
	                if (libraryDevice) {
	                    // Apply the library device properties
	                    devices = devices.map(d => {
	                        if (d.id !== id) return d;
	                        
	                        // Create a new device with library device properties
	                        return {
	                            ...JSON.parse(JSON.stringify(libraryDevice)),
	                            id: d.id, // Keep the original ID
	                            isEdited: false
	                        };
	                    });
	                    
	                    updateDeviceDisplay();
	                    updateSystemAnalysis();
	                    saveDevices();
	                }
	            }
	        } catch (e) {
	            console.error('Error loading device from library:', e);
	        }
	    } else {
	        // Normal template handling
	        // Get the template name first
	        const templateName = value !== 'Custom' ? DEVICE_TEMPLATES[value].name : 'Custom Device';
	        
	        // Update device with new template
	        devices = devices.map(d => {
	            if (d.id !== id) return d;
	            
	            const baseDevice = { ...d };
	            
	            if (value !== 'Custom') {
	                // Update device with template and its name
	                return { 
	                    ...baseDevice, 
	                    ...DEVICE_TEMPLATES[value],
	                    id: d.id,
	                    template: value,
	                    name: templateName, // Use template name
	                    isEdited: false
	                };
	            } else {
	                return {
	                    ...baseDevice,
	                    template: 'Custom',
	                    name: 'Custom Device',
	                    isEdited: false
	                };
	            }
	        });
	        
	        updateDeviceDisplay();
	        updateSystemAnalysis();
	        saveDevices();
	    }
	}
        // Filtering function
        const filterTable = () => {
            const modelFilter = document.getElementById('modelFilter').value.toLowerCase();
            const hardwareFilter = document.getElementById('hardwareFilter').value.toLowerCase();
            const quantizationFilter = document.getElementById('quantizationFilter').value.toLowerCase();

            const filteredData = data.filter(row => {
                return (!modelFilter || row.model.toLowerCase().includes(modelFilter)) &&
                       (!hardwareFilter || (row.hardware && row.hardware.toLowerCase().includes(hardwareFilter))) &&
                       (!quantizationFilter || (row.quantization && row.quantization.toLowerCase().includes(quantizationFilter)));
            });

            renderTable(filteredData);
        };

        // Event listeners
        document.querySelectorAll('th[data-sort]').forEach(th => {
            th.addEventListener('click', () => {
                const column = th.dataset.sort;
                const currentDirection = th.classList.contains('asc') ? 'desc' : 'asc';
                
                // Remove all sort indicators
                document.querySelectorAll('th').forEach(el => {
                    el.classList.remove('asc', 'desc');
                });
                
                th.classList.add(currentDirection);
                sortTable(column, currentDirection);
            });
        });

        document.getElementById('modelFilter').addEventListener('input', filterTable);
        document.getElementById('hardwareFilter').addEventListener('input', filterTable);
        document.getElementById('quantizationFilter').addEventListener('input', filterTable);

	document.addEventListener('DOMContentLoaded', function() {
	    const modelPresetSelect = document.getElementById('modelPreset');
	    modelPresetSelect.innerHTML = '<option value="">Custom</option>';
	    
	    // Add options from MODEL_PRESETS object
	    Object.keys(MODEL_PRESETS).forEach(key => {
	        const option = document.createElement('option');
	        option.value = key;
	        option.textContent = key.split('_').map(word => 
	            word.charAt(0).toUpperCase() + word.slice(1)
	        ).join(' ').replace(/([0-9]+[a-z])/i, match => match.toUpperCase());
	        
	        // Set Llama 3 8B as selected by default
	        if (key === 'llama3_8b') {
	            option.selected = true;
	        }
	        
	        modelPresetSelect.appendChild(option);
	    });
	    
	    renderTable(data);
	    
	    if(localStorage.getItem('savedDevices')) {
	        document.getElementById('loadDevicesBtn').removeAttribute('disabled');
	    } else {
	        document.getElementById('loadDevicesBtn').setAttribute('disabled', true);
	    }
	});
        
    </script>
</body>
</html>
