<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ML System Bottleneck Analyzer - Hardware Performance Analysis Tool</title>
    
    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAzMiAzMiI+CiAgPGRlZnM+CiAgICA8bGluZWFyR3JhZGllbnQgaWQ9ImdyYWQiIHgxPSIwJSIgeTE9IjAlIiB4Mj0iMTAwJSIgeTI9IjEwMCUiPgogICAgICA8c3RvcCBvZmZzZXQ9IjAlIiBzdHlsZT0ic3RvcC1jb2xvcjojNjM2NmYxO3N0b3Atb3BhY2l0eToxIiAvPgogICAgICA8c3RvcCBvZmZzZXQ9IjEwMCUiIHN0eWxlPSJzdG9wLWNvbG9yOiM0ZjQ2ZTU7c3RvcC1vcGFjaXR5OjEiIC8+CiAgICA8L2xpbmVhckdyYWRpZW50PgogIDwvZGVmcz4KICA8cmVjdCB4PSI0IiB5PSI0IiB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHJ4PSI0IiBmaWxsPSJ1cmwoI2dyYWQpIi8+CiAgPHBhdGggZD0iTTEwIDE2IEwxNCAyMCBMMjIgMTIiIHN0cm9rZT0id2hpdGUiIHN0cm9rZS13aWR0aD0iMiIgZmlsbD0ibm9uZSIvPgogIDxwYXRoIGQ9Ik04IDIyIEwyNCAyMiIgc3Ryb2tlPSJ3aGl0ZSIgc3Ryb2tlLXdpZHRoPSIyIiBmaWxsPSJub25lIi8+CiAgPHBhdGggZD0iTTggMjYgTDIwIDI2IiBzdHJva2U9IndoaXRlIiBzdHJva2Utd2lkdGg9IjEuNSIgZmlsbD0ibm9uZSIgb3BhY2l0eT0iMC43Ii8+Cjwvc3ZnPg==">

    <!-- Primary Meta Tags -->
    <meta name="title" content="ML System Bottleneck Analyzer - Hardware Performance Analysis Tool">
    <meta name="description" content="Analyze and visualize hardware bottlenecks in machine learning systems. Get real-time insights into memory, bandwidth, and compute utilization across multiple devices.">
    <meta name="keywords" content="ML, machine learning, hardware bottleneck, performance analysis, GPU, CPU, token rate, memory utilization, bandwidth analysis, compute utilization">
    <meta name="author" content="Steve Seguin">
    <meta name="theme-color" content="#6366f1">

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://mlbottleneck.com/">
    <meta property="og:title" content="ML System Bottleneck Analyzer">
    <meta property="og:description" content="Web-based tool for analyzing hardware bottlenecks in ML systems. Visualize performance limitations across distributed setups - right in your browser!">
    <meta property="og:image" content="data:image/svg+xml;base64,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">

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://mlbottleneck.com/">
    <meta property="twitter:title" content="ML System Bottleneck Analyzer">
    <meta property="twitter:description" content="Web-based tool for analyzing hardware bottlenecks in ML systems. Visualize performance limitations across distributed setups - right in your browser!">
    <meta property="twitter:image" content="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxMjAwIiBoZWlnaHQ9IjYzMCIgdmlld0JveD0iMCAwIDEyMDAgNjMwIj48ZGVmcz48bGluZWFyR3JhZGllbnQgaWQ9ImJnR3JhZCIgeDE9IjAlIiB5MT0iMCUiIHgyPSIxMDAlIiB5Mj0iMTAwJSI+PHN0b3Agb2Zmc2V0PSIwJSIgc3R5bGU9InN0b3AtY29sb3I6IzFlMjkzYjtzdG9wLW9wYWNpdHk6MSIgLz48c3RvcCBvZmZzZXQ9IjEwMCUiIHN0eWxlPSJzdG9wLWNvbG9yOiMwZjE3MmE7c3RvcC1vcGFjaXR5OjEiIC8+PC9saW5lYXJHcmFkaWVudD48bGluZWFyR3JhZGllbnQgaWQ9InByaW1hcnlHcmFkIiB4MT0iMCUiIHkxPSIwJSIgeDI9IjEwMCUiIHkyPSIwJSI+PHN0b3Agb2Zmc2V0PSIwJSIgc3R5bGU9InN0b3AtY29sb3I6IzYzNjZmMTtzdG9wLW9wYWNpdHk6MSIgLz48c3RvcCBvZmZzZXQ9IjEwMCUiIHN0eWxlPSJzdG9wLWNvbG9yOiM0ZjQ2ZTU7c3RvcC1vcGFjaXR5OjEiIC8+PC9saW5lYXJHcmFkaWVudD48L2RlZnM+PHJlY3Qgd2lkdGg9IjEyMDAiIGhlaWdodD0iNjMwIiBmaWxsPSJ1cmwoI2JnR3JhZCkiLz48ZyBzdHJva2U9InVybCgjcHJpbWFyeUdyYWQpIiBzdHJva2Utd2lkdGg9IjIiIG9wYWNpdHk9IjAuMSI+PHBhdGggZD0iTTAgMTAwIEgxMjAwIiAvPjxwYXRoIGQ9Ik0wIDIwMCBIMTIwMCIgLz48cGF0aCBkPSJNMCAzMDAgSDEyMDAiIC8+PHBhdGggZD0iTTAgNDAwIEgxMjAwIiAvPjxwYXRoIGQ9Ik0wIDUwMCBIMTIwMCIgLz48cGF0aCBkPSJNMTAwIDAgVjYzMCIgLz48cGF0aCBkPSJNMzAwIDAgVjYzMCIgLz48cGF0aCBkPSJNNTAwIDAgVjYzMCIgLz48cGF0aCBkPSJNNzAwIDAgVjYzMCIgLz48cGF0aCBkPSJNOTAwIDAgVjYzMCIgLz48cGF0aCBkPSJNMTEwMCAwIFY2MzAiIC8+PC9nPjxnIHRyYW5zZm9ybT0idHJhbnNsYXRlKDEwMCwgMTgwKSI+PGcgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMCwgMCkiPjxyZWN0IHg9IjUwIiB5PSIyMCIgd2lkdGg9IjQwMCIgaGVpZ2h0PSI0MCIgcng9IjQiIGZpbGw9IiM5NGEzYjgiIG9wYWNpdHk9IjAuMiIvPjxyZWN0IHg9IjUwIiB5PSIyMCIgd2lkdGg9IjMyMCIgaGVpZ2h0PSI0MCIgcng9IjQiIGZpbGw9InVybCgjcHJpbWFyeUdyYWQpIi8+PHRleHQgeD0iMjAiIHk9IjQ1IiBmaWxsPSIjZTJlOGYwIiBmb250LWZhbWlseT0ic3lzdGVtLXVpIiBmb250LXNpemU9IjE2Ij5NZW1vcnk8L3RleHQ+PHRleHQgeD0iNDYwIiB5PSI0NSIgZmlsbD0iI2UyZThmMCIgZm9udC1mYW1pbHk9InN5c3RlbS11aSIgZm9udC1zaXplPSIxNiI+ODAlPC90ZXh0PjwvZz48ZyB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLCA4MCkiPjxyZWN0IHg9IjUwIiB5PSIyMCIgd2lkdGg9IjQwMCIgaGVpZ2h0PSI0MCIgcng9IjQiIGZpbGw9IiM5NGEzYjgiIG9wYWNpdHk9IjAuMiIvPjxyZWN0IHg9IjUwIiB5PSIyMCIgd2lkdGg9IjI4MCIgaGVpZ2h0PSI0MCIgcng9IjQiIGZpbGw9InVybCgjcHJpbWFyeUdyYWQpIi8+PHRleHQgeD0iMjAiIHk9IjQ1IiBmaWxsPSIjZTJlOGYwIiBmb250LWZhbWlseT0ic3lzdGVtLXVpIiBmb250LXNpemU9IjE2Ij5Db21wdXRlPC90ZXh0Pjx0ZXh0IHg9IjQ2MCIgeT0iNDUiIGZpbGw9IiNlMmU4ZjAiIGZvbnQtZmFtaWx5PSJzeXN0ZW0tdWkiIGZvbnQtc2l6ZT0iMTYiPjcwJTwvdGV4dD48L2c+PGcgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMCwgMTYwKSI+PHJlY3QgeD0iNTAiIHk9IjIwIiB3aWR0aD0iNDAwIiBoZWlnaHQ9IjQwIiByeD0iNCIgZmlsbD0iIzk0YTNiOCIgb3BhY2l0eT0iMC4yIi8+PHJlY3QgeD0iNTAiIHk9IjIwIiB3aWR0aD0iMjAwIiBoZWlnaHQ9IjQwIiByeD0iNCIgZmlsbD0idXJsKCNwcmltYXJ5R3JhZCkiLz48dGV4dCB4PSIyMCIgeT0iNDUiIGZpbGw9IiNlMmU4ZjAiIGZvbnQtZmFtaWx5PSJzeXN0ZW0tdWkiIGZvbnQtc2l6ZT0iMTYiPkJhbmR3aWR0aDwvdGV4dD48dGV4dCB4PSI0NjAiIHk9IjQ1IiBmaWxsPSIjZTJlOGYwIiBmb250LWZhbWlseT0ic3lzdGVtLXVpIiBmb250LXNpemU9IjE2Ij41MCU8L3RleHQ+PC9nPjwvZz48ZyB0cmFuc2Zvcm09InRyYW5zbGF0ZSg2MDAsIDI0MCkiPjx0ZXh0IHg9IjAiIHk9IjAiIGZpbGw9IiNmZmZmZmYiIGZvbnQtZmFtaWx5PSJzeXN0ZW0tdWkiIGZvbnQtc2l6ZT0iNDgiIGZvbnQtd2VpZ2h0PSI3MDAiPk1MIFN5c3RlbTwvdGV4dD48dGV4dCB4PSIwIiB5PSI2MCIgZmlsbD0iI2ZmZmZmZiIgZm9udC1mYW1pbHk9InN5c3RlbS11aSIgZm9udC1zaXplPSI0OCIgZm9udC13ZWlnaHQ9IjcwMCI+Qm90dGxlbmVjayBBbmFseXplcjwvdGV4dD48dGV4dCB4PSIwIiB5PSIxMjAiIGZpbGw9IiM5NGEzYjgiIGZvbnQtZmFtaWx5PSJzeXN0ZW0tdWkiIGZvbnQtc2l6ZT0iMjQiPlZpc3VhbGl6ZSBhbmQgb3B0aW1pemUgeW91cjwvdGV4dD48dGV4dCB4PSIwIiB5PSIxNTUiIGZpbGw9IiM5NGEzYjgiIGZvbnQtZmFtaWx5PSJzeXN0ZW0tdWkiIGZvbnQtc2l6ZT0iMjQiPm1hY2hpbmUgbGVhcm5pbmcgaW5mcmFzdHJ1Y3R1cmU8L3RleHQ+PC9nPjwvc3ZnPg==">
    <meta name="twitter:creator" content="@xyster">

    <!-- Additional Meta -->
    <meta name="application-name" content="ML Bottleneck Analyzer">
    <meta name="apple-mobile-web-app-title" content="ML Bottleneck">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="default">
    <meta name="format-detection" content="telephone=no">
    <meta name="mobile-web-app-capable" content="yes">

    <!-- Preload Critical Resources -->
    <link rel="preconnect" href="https://cdnjs.cloudflare.com">

    <!-- Chart.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/3.7.0/chart.min.js"></script>
	<!-- Structured Data for Google -->
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "WebApplication",
      "name": "ML System Bottleneck Analyzer",
      "description": "Web-based tool for analyzing hardware bottlenecks in machine learning systems. Visualize performance limitations across distributed setups - right in your browser!",
      "url": "https://mlbottleneck.com",
      "author": {
        "@type": "Person",
        "name": "Steve Seguin"
      },
      "applicationCategory": "Machine Learning Tools",
      "operatingSystem": "Any",
      "browserRequirements": "Requires JavaScript",
      "offers": {
        "@type": "Offer",
        "price": "0",
        "priceCurrency": "USD"
      }
    }
    </script>
    <style>
	
@media (prefers-color-scheme: dark) {
:root {
    --primary: #6366f1;
    --primary-hover: #4f46e5;
    --destructive: #ef4444;
    --destructive-hover: #dc2626;
    --border: #1e293b;
    --background: #0b0f1a;
    --card: #1e293b;
    --text: #f8fafc;
    --text-secondary: #94a3b8;
    --radius: 0.5rem;
    --shadow: 0 4px 6px -1px rgb(0 0 0 / 0.3), 0 2px 4px -2px rgb(0 0 0 / 0.2);
    --transition: all 0.2s cubic-bezier(0.4, 0, 0.2, 1);
}

* {
    box-sizing: border-box;
}

body {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, system-ui, sans-serif;
    margin: 0;
    padding: 2rem;
    max-width: 1400px;
    margin: 0 auto;
    background: var(--background);
    color: var(--text);
    line-height: 1.5;
}

h1 {
    font-size: 2.25rem;
    font-weight: 700;
    margin: 2rem 0;
    background: linear-gradient(135deg, var(--primary), var(--primary-hover));
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    letter-spacing: -0.025em;
}

h2 {
    font-size: 1.5rem;
    font-weight: 600;
    margin: 1.5rem 0;
    color: var(--text);
    letter-spacing: -0.025em;
}

h3 {
    font-size: 1.25rem;
    font-weight: 600;
    margin: 1rem 0;
    color: var(--text);
}

a {
    color: var(--primary);
    text-decoration: none;
    transition: var(--transition);
}

a:hover {
    color: var(--primary-hover);
    text-decoration: underline;
}

.card {
    background: var(--card);
    border: 1px solid var(--border);
    border-radius: var(--radius);
    padding: 1.5rem;
    margin-bottom: 1.5rem;
    box-shadow: var(--shadow);
    transition: var(--transition);
    backdrop-filter: blur(8px);
}

.card:hover {
    transform: translateY(-2px);
    box-shadow: 0 10px 15px -3px rgb(0 0 0 / 0.3), 0 4px 6px -4px rgb(0 0 0 / 0.2);
    border-color: var(--primary);
}

.grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(min(400px, 100%), 1fr));
    gap: 1.5rem;
    margin: 2rem 0;
}

.device {
    background: var(--background);
    border: 1px solid var(--border);
    padding: 1.5rem;
    margin-bottom: 1rem;
    border-radius: var(--radius);
    transition: var(--transition);
}

.device:hover {
    border-color: var(--primary);
    transform: translateY(-1px);
}

.button {
    background: var(--primary);
    color: white;
    border: none;
    padding: 0.75rem 1.5rem;
    border-radius: var(--radius);
    cursor: pointer;
    font-weight: 500;
    transition: var(--transition);
    font-size: 0.875rem;
    line-height: 1.25rem;
}

.button:hover {
    background: var(--primary-hover);
    transform: translateY(-1px);
}

.button:active {
    transform: translateY(0);
}

.button:disabled {
    opacity: 0.5;
    cursor: not-allowed;
}

.button-destructive {
    background: var(--destructive);
}

.button-destructive:hover {
    background: var(--destructive-hover);
}

.input, select {
    width: 100%;
    padding: 0.75rem;
    border: 1px solid var(--border);
    border-radius: var(--radius);
    margin-bottom: 1rem;
    transition: var(--transition);
    color: var(--text);
    background: var(--background);
    font-size: 0.875rem;
    line-height: 1.25rem;
}

.input:hover, select:hover {
    border-color: var(--primary);
}

.input:focus, select:focus {
    outline: none;
    border-color: var(--primary);
    box-shadow: 0 0 0 3px rgba(99, 102, 241, 0.1);
}

.input:disabled, select:disabled {
    background: #334155;
    cursor: not-allowed;
    opacity: 0.75;
}

.alert {
    background: #881337;
    border: 1px solid var(--destructive);
    padding: 1.5rem;
    border-radius: var(--radius);
    margin-bottom: 1.5rem;
    color: #fecdd3;
}

.device-grid {
    display: grid;
    grid-template-columns: repeat(2, 1fr);
    gap: 1rem;
}

label {
    display: block;
    margin-bottom: 0.5rem;
    font-size: 0.875rem;
    font-weight: 500;
    color: var(--text-secondary);
}

.chart-container {
    height: 400px;
    margin-bottom: 1.5rem;
    padding: 1rem;
    background: var(--background);
    border-radius: var(--radius);
    border: 1px solid var(--border);
    transition: var(--transition);
}

.chart-container:hover {
    border-color: var(--primary);
}

.inline-select-group {
    display: flex;
    gap: 1rem;
    margin-bottom: 1rem;
    align-items: center;
}

.inline-select-group label {
    margin-bottom: 0;
    margin-right: 0.5rem;
    flex-shrink: 0;
    width: auto;
    white-space: nowrap;
}

.inline-select-group select {
    flex-grow: 1;
    margin-bottom: 0;
    min-width: 0;
}

table {
    width: 100%;
    margin: 1.5rem 0;
    border-collapse: separate;
    border-spacing: 0;
    border: 1px solid var(--border);
    border-radius: var(--radius);
    overflow: hidden;
    background: var(--card);
}

th, td {
    padding: 0.75rem 1rem;
    text-align: left;
    border-bottom: 1px solid var(--border);
    font-size: 0.875rem;
}

th {
    background: var(--background);
    font-weight: 600;
    position: relative;
    cursor: pointer;
    user-select: none;
    transition: var(--transition);
}

th:hover {
    background: #334155;
}

th::after {
    content: '';
    position: absolute;
    right: 0.75rem;
    top: 50%;
    transform: translateY(-50%);
    opacity: 0.5;
}

th.asc::after {
    content: '▲';
}

th.desc::after {
    content: '▼';
}

tr:last-child td {
    border-bottom: none;
}

tr:nth-child(even) {
    background-color: rgba(30, 41, 59, 0.5);
}

tr:hover {
    background-color: rgba(99, 102, 241, 0.1);
}

.filters {
    margin: 1.5rem 0;
    display: flex;
    gap: 1rem;
    flex-wrap: wrap;
    background: var(--card);
    padding: 1.5rem;
    border-radius: var(--radius);
    border: 1px solid var(--border);
}

.filter-group {
    display: flex;
    flex-direction: column;
    gap: 0.5rem;
    flex: 1;
    min-width: 200px;
}

@media (max-width: 768px) {
    body {
        padding: 1rem;
    }

    .grid {
        grid-template-columns: 1fr;
    }

    .device-grid {
        grid-template-columns: 1fr;
    }

    .inline-select-group {
        flex-direction: column;
        gap: 0.5rem;
    }

    .inline-select-group select {
        width: 100%;
    }

    .filters {
        flex-direction: column;
    }

    .filter-group {
        width: 100%;
    }

    h1 {
        font-size: 1.75rem;
    }

    h2 {
        font-size: 1.25rem;
    }
}
}
@media (prefers-color-scheme: light) {
 :root {
    --primary: #6366f1;
    --primary-hover: #4f46e5;
    --destructive: #ef4444;
    --destructive-hover: #dc2626;
    --border: #e2e8f0;
    --background: #ffffff;
    --card: #ffffff;
    --text: #0f172a;
    --text-secondary: #475569;
    --radius: 0.75rem;
    --shadow: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);
}

body {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, system-ui, sans-serif;
    margin: 0;
    padding: 2rem;
    max-width: 1400px;
    margin: 0 auto;
    background: #f8fafc;
    color: var(--text);
}

h1 {
    font-size: 2.25rem;
    font-weight: 700;
    margin-bottom: 2rem;
    background: linear-gradient(to right, var(--primary), var(--primary-hover));
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
}

h2 {
    font-size: 1.5rem;
    font-weight: 600;
    margin-bottom: 1.5rem;
    color: var(--text);
}

h3 {
    font-size: 1.25rem;
    font-weight: 600;
    margin-bottom: 1rem;
    color: var(--text);
}

.card {
    background: var(--card);
    border: 1px solid var(--border);
    border-radius: var(--radius);
    padding: 1.5rem;
    margin-bottom: 1.5rem;
    box-shadow: var(--shadow);
    transition: transform 0.2s, box-shadow 0.2s;
}

.card:hover {
    transform: translateY(-2px);
    box-shadow: 0 10px 15px -3px rgb(0 0 0 / 0.1), 0 4px 6px -4px rgb(0 0 0 / 0.1);
}

.grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
    gap: 1.5rem;
}

.device {
    background: var(--background);
    border: 1px solid var(--border);
    padding: 1.5rem;
    margin-bottom: 1rem;
    border-radius: var(--radius);
    transition: border-color 0.2s;
}

.device:hover {
    border-color: var(--primary);
}

.button {
    background: var(--primary);
    color: white;
    border: none;
    padding: 0.75rem 1.5rem;
    border-radius: var(--radius);
    cursor: pointer;
    font-weight: 500;
    transition: background-color 0.2s;
}

.button:hover {
    background: var(--primary-hover);
}

.button-destructive {
    background: var(--destructive);
}

.button-destructive:hover {
    background: var(--destructive-hover);
}

.input, select {
    width: 100%;
    padding: 0.75rem;
    border: 1px solid var(--border);
    border-radius: var(--radius);
    margin-bottom: 1rem;
    transition: border-color 0.2s, box-shadow 0.2s;
    color: var(--text);
    background: var(--background);
}

.input:focus, select:focus {
    outline: none;
    border-color: var(--primary);
    box-shadow: 0 0 0 3px rgba(99, 102, 241, 0.1);
}

.input:disabled, select:disabled {
    background: #f1f5f9;
    cursor: not-allowed;
}

.alert {
    background: #fef2f2;
    border: 1px solid var(--destructive);
    padding: 1.5rem;
    border-radius: var(--radius);
    margin-bottom: 1.5rem;
    color: var(--destructive);
}

.device-grid {
    display: grid;
    grid-template-columns: repeat(2, 1fr);
    gap: 1rem;
}

label {
    display: block;
    margin-bottom: 0.5rem;
    font-size: 0.875rem;
    font-weight: 500;
    color: var(--text-secondary);
}

.chart-container {
    height: 400px;
    margin-bottom: 1.5rem;
    padding: 1rem;
    background: var(--background);
    border-radius: var(--radius);
    border: 1px solid var(--border);
}

.inline-select-group {
    display: flex;
    gap: 1rem;
    margin-bottom: 1rem;
    align-items: center;
}

.inline-select-group label {
    margin-bottom: 0;
    margin-right: 0.5rem;
    flex-shrink: 0;
    width: auto;
}

.inline-select-group select {
    flex-grow: 1;
    margin-bottom: 0;
}

table {
	border-collapse: collapse;
	width: 100%;
	margin: 20px 0;
	font-family: Arial, sans-serif;
}
th, td {
	border: 1px solid #ddd;
	padding: 8px;
	text-align: left;
}
th {
	background-color: #f5f5f5;
	position: relative;
	cursor: pointer;
}
th:hover {
	background-color: #eee;
}
th::after {
	content: '';
	position: absolute;
	right: 8px;
	top: 50%;
	transform: translateY(-50%);
}
th.asc::after {
	content: '▲';
}
th.desc::after {
	content: '▼';
}
tr:nth-child(even) {
	background-color: #f9f9f9;
}
.filters {
	margin: 20px 0;
	display: flex;
	gap: 10px;
	flex-wrap: wrap;
}
.filter-group {
	display: flex;
	flex-direction: column;
	gap: 5px;
}
input, select {
	padding: 5px;
	border: 1px solid #ddd;
	border-radius: 4px;
}

@media (max-width: 768px) {
    body {
        padding: 1rem;
    }

    .grid {
        grid-template-columns: 1fr;
    }

    .device-grid {
        grid-template-columns: 1fr;
    }

    .inline-select-group {
        flex-direction: column;
        gap: 0.5rem;
    }

    .inline-select-group select {
        width: 100%;
    }
}

 
}
    </style>
</head>
<body>
    <h1>ML System Bottleneck Analyzer</h1>

    <div class="grid">
        <div class="card">
            <h2>Model Configuration</h2>
            <div id="modelConfig">
                <div class="inline-select-group">
                    <label for="modelPreset">Model Preset</label>
                    <select id="modelPreset" class="input">
                        <option value="">Custom</option>
                        <option value="llama3_8b" selected>Llama 3 8B</option>
                        <option value="llama3_70b">Llama 3 70B</option>
                        <option value="mistral_7b">Mistral 7B</option>
                        <option value="deepseek_v3">DeepSeek V3 (700B)</option>
                        <option value="large_model_400b">Large Model (400B+)</option>
                        <option value="very_large_model_1t">Very Large Model (1T+)</option>
                    </select>

                    <label for="quantizationType">Quantization</label>
                    <select id="quantizationType" class="input">
                        <option value="q4">Q4</option>
                        <option value="int8">INT8</option>
                        <option value="float16" selected>FP16</option>
                        <option value="bfloat16">BF16</option>
                        <option value="float32">FP32</option>
                    </select>
                </div>

                <label>Total Parameters (B)</label>
                <input type="number" id="totalParamsB" class="input" value="400">

                <label>Batch Size</label>
                <input type="number" id="batchSize" class="input" value="1">

                <label>Sequence Length</label>
                <input type="number" id="seqLength" class="input" value="2048">

                <label>Hidden Size</label>
                <input type="number" id="hiddenSize" class="input" value="16384">

                <label>Number of Layers</label>
                <input type="number" id="numLayers" class="input" value="120">

                <label>Number of Heads</label>
                <input type="number" id="numHeads" class="input" value="128">

                <label style="display: none;">Data Type</label>
                <select id="dtype" class="input" style="display: none;">
                    <option value="float32">float32</option>
                    <option value="bfloat16" selected>bfloat16</option>
                    <option value="float16">float16</option>
                    <option value="int8">int8</option>
                    <option value="q4">q4</option>
                </select>

                <label>Parallelism Strategy</label>
                <select id="parallelismStrategy" class="input">
                    <option value="pipeline">Pipeline Parallelism</option>
                    <option value="tensor">Tensor Parallelism</option>
                </select>
            </div>
        </div>

        <div class="card">
            <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 1rem;">
                <h2>Devices</h2>
                <button class="button" onclick="addDevice()">Add Device</button>
            </div>
            <div id="devices"></div>
        </div>
    </div>
	
	<div id="alerts"></div>

    <div class="grid">
        <div class="card">
            <h2>Resource Utilization</h2>
            <div class="chart-container">
                <canvas id="utilizationChart"></canvas>
            </div>
        </div>

        <div class="card">
            <h2>System Analysis <small>(Token rates are approximations)</small></h2>
            <div id="systemAnalysis"></div>
        </div>
    </div>

    <h1>Real-world results are below for reference</h1>
    <div class="filters">
        <div class="filter-group">
            <label for="modelFilter">Model:</label>
            <input type="text" id="modelFilter" placeholder="Filter models...">
        </div>
        <div class="filter-group">
            <label for="hardwareFilter">Hardware:</label>
            <input type="text" id="hardwareFilter" placeholder="Filter hardware...">
        </div>
        <div class="filter-group">
            <label for="quantizationFilter">Quantization:</label>
            <input type="text" id="quantizationFilter" placeholder="Filter quantization...">
        </div>
    </div>

    <table id="llmTable">
        <thead>
            <tr>
                <th data-sort="model">Model</th>
                <th data-sort="quantization">Quantization</th>
                <th data-sort="framework">Framework</th>
                <th data-sort="hardware">Hardware</th>
                <th data-sort="batchSize">Batch Size</th>
                <th data-sort="seqLength">Sequence Length</th>
                <th data-sort="tokenRateBatch">Token Rate (Batch)</th>
                <th data-sort="tokenRateSingle">Token Rate (Single)</th>
                <th data-sort="source">Source</th>
            </tr>
        </thead>
        <tbody></tbody>
    </table>

    <script>
        const DTYPE_SIZES = {
            'float32': 4,
            'bfloat16': 2,
            'float16': 2,
            'int8': 1,
            'q4': 0.5
        };
        const MODEL_PRESETS = {
            'llama3_8b': {
                'q4': {
                    totalParamsB: 8,
                    hiddenSize: 3072,
                    numLayers: 32,
                    numHeads: 32,
                    dtype: 'q4'
                },
                'int8': {
                    totalParamsB: 8,
                    hiddenSize: 3072,
                    numLayers: 32,
                    numHeads: 32,
                    dtype: 'int8'
                },
                'float16': {
                    totalParamsB: 8,
                    hiddenSize: 3072,
                    numLayers: 32,
                    numHeads: 32,
                    dtype: 'float16'
                },
                'bfloat16': {
                    totalParamsB: 8,
                    hiddenSize: 3072,
                    numLayers: 32,
                    numHeads: 32,
                    dtype: 'bfloat16'
                },
                'float32': {
                    totalParamsB: 8,
                    hiddenSize: 3072,
                    numLayers: 32,
                    numHeads: 32,
                    dtype: 'float32'
                },
            },
            'llama3_70b': {
                'q4': {
                    totalParamsB: 70,
                    hiddenSize: 8192,
                    numLayers: 80,
                    numHeads: 64,
                    dtype: 'q4'
                },
                'int8': {
                    totalParamsB: 70,
                    hiddenSize: 8192,
                    numLayers: 80,
                    numHeads: 64,
                    dtype: 'int8'
                },
                'float16': {
                    totalParamsB: 70,
                    hiddenSize: 8192,
                    numLayers: 80,
                    numHeads: 64,
                    dtype: 'float16'
                },
                'bfloat16': {
                    totalParamsB: 70,
                    hiddenSize: 8192,
                    numLayers: 80,
                    numHeads: 64,
                    dtype: 'bfloat16'
                },
                'float32': {
                    totalParamsB: 70,
                    hiddenSize: 8192,
                    numLayers: 80,
                    numHeads: 64,
                    dtype: 'float32'
                }
            },
            'mistral_7b': {
                'q4': {
                    totalParamsB: 7,
                    hiddenSize: 4096,
                    numLayers: 32,
                    numHeads: 32,
                    dtype: 'q4'
                },
                'int8': {
                    totalParamsB: 7,
                    hiddenSize: 4096,
                    numLayers: 32,
                    numHeads: 32,
                    dtype: 'int8'
                },
                'float16': {
                    totalParamsB: 7,
                    hiddenSize: 4096,
                    numLayers: 32,
                    numHeads: 32,
                    dtype: 'float16'
                },
                'bfloat16': {
                    totalParamsB: 7,
                    hiddenSize: 4096,
                    numLayers: 32,
                    numHeads: 32,
                    dtype: 'bfloat16'
                },
                'float32': {
                    totalParamsB: 7,
                    hiddenSize: 4096,
                    numLayers: 32,
                    numHeads: 32,
                    dtype: 'float32'
                }
            },
            'deepseek_v3': {
                'float16': {
                    totalParamsB: 671,
                    hiddenSize: 8192,
                    numLayers: 64,
                    numHeads: 64,
                    dtype: 'float16'
                },
                'bfloat16': {
                    totalParamsB: 671,
                    hiddenSize: 8192,
                    numLayers: 64,
                    numHeads: 64,
                    dtype: 'bfloat16'
                }
            },
            'large_model_400b': {
                'float16': {
                    totalParamsB: 400,
                    hiddenSize: 16384,
                    numLayers: 120,
                    numHeads: 128,
                    dtype: 'float16'
                },
                'bfloat16': {
                    totalParamsB: 400,
                    hiddenSize: 16384,
                    numLayers: 120,
                    numHeads: 128,
                    dtype: 'bfloat16'
                }
            },
            'very_large_model_1t': {
                'float16': {
                    totalParamsB: 1000,
                    hiddenSize: 32768,
                    numLayers: 200,
                    numHeads: 256,
                    dtype: 'float16'
                },
                'bfloat16': {
                    totalParamsB: 1000,
                    hiddenSize: 32768,
                    numLayers: 200,
                    numHeads: 256,
                    dtype: 'bfloat16'
                }
            }
        };
        const DEVICE_TEMPLATES = {
			'A100': {
				name: 'NVIDIA A100',
				memoryGB: 80,
				localBandwidthGBps: 1935,
				networkBandwidthGBps: 300,
				computeTFlops: {
					'float32': 156,
					'float16': 312,
					'bfloat16': 312,  // Same as float16
					'int8': 624,
					'q4': 1000
				},
				type: 'GPU'
			},
			'H100': {
				name: 'NVIDIA H100',
				memoryGB: 120,
				localBandwidthGBps: 3350,
				networkBandwidthGBps: 450,
				computeTFlops: {
					'float32': 500,
					'float16': 989,
					'bfloat16': 989,  // Same as float16
					'int8': 1979,
					'q4': 2500
				},
				type: 'GPU'
			},
			'RTX 4090': {
				name: 'RTX 4090',
				memoryGB: 24,
				localBandwidthGBps: 1008,
				networkBandwidthGBps: 32,
				computeTFlops: {
					'float32': 83,
					'float16': 166,
					'bfloat16': 83,  // Falls back to float32
					'int8': 332,
					'q4': 500
				},
				type: 'GPU'
			},
			'RTX 4070': {
				name: 'RTX 4070',
				memoryGB: 12,
				localBandwidthGBps: 504,
				networkBandwidthGBps: 32,
				computeTFlops: {
					'float32': 29,
					'float16': 58,
					'int8': 116,
					'q4': 175
				},
				type: 'GPU'
			},
			'RTX 5090 (Projected)': {
				name: 'RTX 5090 (Projected)',
				memoryGB: 32,
				localBandwidthGBps: 1500,
				networkBandwidthGBps: 64,
				computeTFlops: {
					'float32': 105,
					'float16': 210,
					'int8': 420,
					'q4': 630
				},
				type: 'GPU'
			},
			'Intel Xeon CPU (High-End)': {
				name: 'Intel Xeon CPU (High-End)',
				memoryGB: 256,
				localBandwidthGBps: 80,
				networkBandwidthGBps: 25,
				computeTFlops: {
					'float32': 2,
					'bfloat16': 4,  // Supported natively
					'float16': 4,
					'int8': 8,
					'q4': 12
				},
				type: 'CPU'
			},
			'AMD EPYC CPU (High-End)': {
				name: 'AMD EPYC CPU (High-End)',
				memoryGB: 256,
				localBandwidthGBps: 90,
				networkBandwidthGBps: 25,
				computeTFlops: {
					'float32': 2.5,
					'bfloat16': 5,
					'float16': 5,
					'int8': 10,
					'q4': 15
				},
				type: 'CPU'
			},
			'AMD Ryzen Integrated Graphics': {
				name: 'AMD Ryzen Integrated Graphics',
				memoryGB: 16,
				localBandwidthGBps: 50,
				networkBandwidthGBps: 2.5 / 8.0,
				computeTFlops: {
					'float32': 0.5,
					'bfloat16': 1.0,
					'float16': 1.0,
					'int8': 2.0,
					'q4': 3.0
				},
				type: 'Integrated GPU'
			},
			'Mac M2 Ultra (192GB)': {
				name: 'Mac M2 Ultra (192GB)',
				memoryGB: 192,
				localBandwidthGBps: 800,
				networkBandwidthGBps: 10,
				computeTFlops: {
					'float32': 16,
					'bfloat16': 32,
					'float16': 32,
					'int8': 64,
					'q4': 96
				},
				type: 'CPU/Integrated GPU'
			},
			'Mac Mini M2 (10G Ethernet)': {
				name: 'Mac Mini M2 (10G)',
				memoryGB: 16,
				localBandwidthGBps: 68,
				networkBandwidthGBps: 10,
				computeTFlops: {
					'float32': 2,
					'bfloat16': 4,
					'float16': 4,
					'int8': 8,
					'q4': 12
				},
				type: 'CPU/Integrated GPU'
			},
			'Raspberry Pi 5 (5G Ethernet)': {
				name: 'Raspberry Pi 5 (5G)',
				memoryGB: 8,
				localBandwidthGBps: 34,
				networkBandwidthGBps: 5 / 8.0,
				computeTFlops: {
					'float32': 0.1,
					'bfloat16': 0.2,
					'float16': 0.2,
					'int8': 0.4,
					'q4': 0.6
				},
				type: 'CPU/Integrated GPU'
			},
			'Desktop PC (2.5G Ethernet)': {
				name: 'Desktop PC (2.5G)',
				memoryGB: 32,
				localBandwidthGBps: 50,
				networkBandwidthGBps: 2.5 / 8.0,
				computeTFlops: {
					'float32': 1,
					'float16': 2,
					'int8': 4,
					'q4': 6
				},
				type: 'CPU/Integrated GPU'
			},
			'NVMe CPU (Gen5)': {
				name: 'NVMe CPU (Gen5)',
				memoryGB: 2000,
				localBandwidthGBps: 14,
				networkBandwidthGBps: 40 / 8,
				computeTFlops: {
					'float32': 2,
					'float16': 4,
					'int8': 8,
					'q4': 12
				},
				type: 'CPU/NVMe'
			},
			'NVMe 4xRAID 5090 (Gen5)': {
				name: 'NVMe 4xRAID GPU (Gen5)',
				memoryGB: 8000,
				localBandwidthGBps: 32,
				networkBandwidthGBps: 40 / 8,
				computeTFlops: {
					'float32': 105,
					'float16': 210,
					'int8': 420,
					'q4': 630
				},
				type: 'GPU/NVMe'
			},
			'Titan RTX + NVMe Gen3': {
				name: 'Titan RTX + NVMe Gen3',
				memoryGB: 4000,
				localBandwidthGBps: 3.5,
				networkBandwidthGBps: 1 / 8,
				computeTFlops: {
					'float32': 16.3,
					'float16': 32.6,
					'int8': 65.2,
					'q4': 98
				},
				type: 'GPU/NVMe'
			},
			'Custom': {
				name: 'Custom Device',
				memoryGB: 192,
				localBandwidthGBps: 50,
				networkBandwidthGBps: 2.5 / 8,
				computeTFlops: {
					'float32': 2,
					'float16': 4,
					'int8': 8,
					'q4': 12
				},
				type: 'Custom'
			}
		};
        let devices = [{
            id: 1,
            name: 'Device 1',
            template: 'Custom',
            ...DEVICE_TEMPLATES["RTX 5090 (Projected)"]
        }];
        let utilizationChart = null;
        function getModelConfig() {
            return {
                modelPreset: document.getElementById('modelPreset').value,
                quantizationType: document.getElementById('quantizationType').value,
                totalParamsB: parseFloat(document.getElementById('totalParamsB').value),
                batchSize: parseFloat(document.getElementById('batchSize').value),
                seqLength: parseFloat(document.getElementById('seqLength').value),
                hiddenSize: parseFloat(document.getElementById('hiddenSize').value),
                numLayers: parseFloat(document.getElementById('numLayers').value),
                numHeads: parseFloat(document.getElementById('numHeads').value),
                dtype: document.getElementById('dtype').value,
                parallelismStrategy: document.getElementById('parallelismStrategy').value
            };
        }
		function calculateMemoryBreakdown(modelConfig, dtypeSize, deviceCount, isPipeline) {
			const paramsMemory = modelConfig.totalParamsB * 1e9 * dtypeSize;
			const kvCacheSizePerLayer = 2 * modelConfig.batchSize * modelConfig.seqLength * 
				(modelConfig.hiddenSize / modelConfig.numHeads) * 
				modelConfig.numHeads * dtypeSize;
			const kvCacheMemory = kvCacheSizePerLayer * modelConfig.numLayers;
			const activationSizePerLayer = modelConfig.batchSize * modelConfig.seqLength * 
				modelConfig.hiddenSize * dtypeSize;
			const activationMemory = activationSizePerLayer * modelConfig.numLayers;
			const attentionMemory = modelConfig.batchSize * (modelConfig.seqLength ** 2) * 
				modelConfig.numHeads * dtypeSize;

			// Adjust memory per device based on parallelism strategy
			const adjustedParamsMemory = isPipeline ? 
				paramsMemory / deviceCount : // Pipeline: divide layers across devices
				paramsMemory; // Tensor: replicate most params
				
			const adjustedKVCacheMemory = kvCacheMemory / deviceCount; // Always divide KV cache
			const adjustedActivationMemory = activationMemory / deviceCount; // Always divide activations
			const adjustedAttentionMemory = attentionMemory / deviceCount; // Always divide attention

			return {
				paramsMemory: adjustedParamsMemory,
				kvCacheMemory: adjustedKVCacheMemory,
				activationMemory: adjustedActivationMemory,
				attentionMemory: adjustedAttentionMemory,
				total: adjustedParamsMemory + adjustedKVCacheMemory + 
					   adjustedActivationMemory + adjustedAttentionMemory
			};
		}
		
		function calculateNetworkTraffic(modelConfig, dtypeSize, deviceCount, isPipeline) {
			if (deviceCount <= 1) return 0;

			const batchSize = modelConfig.batchSize;
			const seqLength = modelConfig.seqLength;
			const hiddenSize = modelConfig.hiddenSize;
			
			if (isPipeline) {
				// Pipeline parallelism: Forward and backward activation passing
				const activationSize = batchSize * seqLength * hiddenSize * dtypeSize;
				// Each layer boundary requires passing activations forward and gradients back
				return activationSize * 2 * (deviceCount - 1);
			} else {
				// Tensor parallelism: All-reduce for gradients and activations
				const gradientSize = modelConfig.totalParamsB * 1e9 * dtypeSize / deviceCount;
				const activationSize = batchSize * seqLength * hiddenSize * dtypeSize;
				// All-reduce communication pattern: (n-1)/n * data_size * 2
				return (deviceCount - 1) * (gradientSize + activationSize) * 2 / deviceCount;
			}
		}

        // Improved FLOPs calculation (more accurate for forward and backward pass)
        function calculateTransformerFlops(modelConfig) {
            const { batchSize, seqLength, hiddenSize, numLayers, numHeads } = modelConfig;

            // Forward pass FLOPs for one layer
            let forwardFlops = 0;

            // Self-Attention
            forwardFlops += 3 * (batchSize * seqLength * hiddenSize * hiddenSize); // Q, K, V projections
            forwardFlops += batchSize * numHeads * seqLength * seqLength * (hiddenSize / numHeads); // Attention scores
            forwardFlops += batchSize * numHeads * seqLength * (hiddenSize / numHeads) * (hiddenSize / numHeads); // Weighted sum
            forwardFlops += batchSize * seqLength * hiddenSize * hiddenSize; // Output projection

            // Feed-Forward Network
            forwardFlops += batchSize * seqLength * hiddenSize * (4 * hiddenSize); // First layer
            forwardFlops += batchSize * seqLength * (4 * hiddenSize) * hiddenSize; // Second layer

            // Multiply by number of layers and then by 3 for forward + backward pass
            return forwardFlops * numLayers * 3;
        }

        function calculateDecodeFlops(modelConfig) {
            const { batchSize, seqLength, hiddenSize, numLayers, numHeads } = modelConfig;

            // Decode FLOPs are dominated by KV cache interactions and are roughly:
            let decodeFlops = 0;

            // KV Cache interaction in self-attention (per layer)
            decodeFlops += 2 * batchSize * seqLength * hiddenSize * hiddenSize; 

            // Feed-Forward Network (remains similar to prefill per token)
            decodeFlops += batchSize * hiddenSize * (4 * hiddenSize); // First layer
            decodeFlops += batchSize * (4 * hiddenSize) * hiddenSize; // Second layer

            return decodeFlops * numLayers; 
        }

        function calculateMetrics() {
			const modelConfig = getModelConfig();
			const dtypeSize = DTYPE_SIZES[modelConfig.quantizationType];
			const isPipeline = modelConfig.parallelismStrategy === 'pipeline';
			const deviceCount = devices.length;

			// Calculate per-device memory and network requirements
			const memoryBreakdown = calculateMemoryBreakdown(modelConfig, dtypeSize, deviceCount, isPipeline);
			const networkTraffic = calculateNetworkTraffic(modelConfig, dtypeSize, deviceCount, isPipeline);

			return devices.map((device, deviceIndex) => {
				// Calculate total FLOPs required for prefill
				
				const quantSpeedFactor = {
					'float32': 1.0,
					'bfloat16': 2.0,
					'float16': 2.0,
					'int8': 2.5,
					'q4': 3.0
				}[modelConfig.quantizationType] || 1.0;

				const totalPrefillFlops = calculateTransformerFlops(modelConfig) / (deviceCount * quantSpeedFactor);
				const theoreticalPrefillComputeTime = totalPrefillFlops / (device.computeTFlops[modelConfig.quantizationType] * 1e12);


				// Network time calculation
				const networkTime = networkTraffic / (device.networkBandwidthGBps * 1e9);
				
				// Memory traffic calculation adjusted for distributed setup
				const memoryTrafficScale = modelConfig.quantizationType === 'q4' ? 1.2 : 1.0; // Q4 has some overhead
				const totalPrefillMemoryTraffic = memoryTrafficScale * (
					memoryBreakdown.paramsMemory + 
					(2 * memoryBreakdown.kvCacheMemory) +
					(3 * memoryBreakdown.activationMemory) +
					(2 * memoryBreakdown.attentionMemory)
				);

				const prefillBandwidthLimitedTime = totalPrefillMemoryTraffic / (device.localBandwidthGBps * 1e9);

				// Include network time in actual execution time
				const overheadFactorPrefill = 2.0;
				const actualPrefillTime = Math.max(
					theoreticalPrefillComputeTime,
					prefillBandwidthLimitedTime,
					networkTime
				) * overheadFactorPrefill;

				// Calculate utilizations
				const prefillComputeUtilization = (theoreticalPrefillComputeTime / actualPrefillTime) * 100;
				const prefillLocalBandwidthUtilization = (prefillBandwidthLimitedTime / actualPrefillTime) * 100;
				const networkBandwidthUtilization = (networkTime / actualPrefillTime) * 100;
				const memoryUtilization = (memoryBreakdown.total / (device.memoryGB * 1e9)) * 100;

				// Calculate bottleneck factor
				const bottleneckFactor = Math.max(
					1,
					prefillComputeUtilization / 100,
					memoryUtilization / 100,
					prefillLocalBandwidthUtilization / 100,
					networkBandwidthUtilization / 100
				);

				// Calculate token throughput
				const prefillTokensPerSecond = modelConfig.batchSize * modelConfig.seqLength / actualPrefillTime;

				// Decode calculations remain similar but scaled by device count
				const decodeFlops = calculateDecodeFlops(modelConfig) / deviceCount;
				const theoreticalDecodeTime = decodeFlops / (device.computeTFlops[modelConfig.quantizationType] * 1e12);

				const decodeMemoryTrafficPerToken = (
					memoryBreakdown.paramsMemory + 
					(2 * modelConfig.seqLength * (modelConfig.hiddenSize / modelConfig.numHeads) * 
					 modelConfig.numHeads * dtypeSize) * modelConfig.numLayers / deviceCount + 
					(4 * modelConfig.hiddenSize * dtypeSize) * modelConfig.numLayers / deviceCount
				) / modelConfig.seqLength;

				const decodeBandwidthLimitedTime = decodeMemoryTrafficPerToken / (device.localBandwidthGBps * 1e9);
				const overheadFactorDecode = 1;
				const actualDecodeTime = Math.max(theoreticalDecodeTime, decodeBandwidthLimitedTime) * 
					overheadFactorDecode;

				return {
					name: device.name,
					memoryUtilization,
					localBandwidthUtilization: prefillLocalBandwidthUtilization,
					networkBandwidthUtilization,
					computeUtilization: prefillComputeUtilization,
					rawMemoryUtilization: memoryUtilization,
					rawLocalBandwidthUtilization: prefillLocalBandwidthUtilization,
					rawNetworkBandwidthUtilization: networkBandwidthUtilization,
					rawComputeUtilization: prefillComputeUtilization,
					bottleneckFactor,
					isBottleneck: bottleneckFactor > 1,
					prefillTokensPerSecond,
					decodeTokensPerSecond: modelConfig.batchSize / actualDecodeTime,
					decodeComputeUtilization: (theoreticalDecodeTime / actualDecodeTime) * 100,
					decodeLocalBandwidthUtilization: (decodeBandwidthLimitedTime / actualDecodeTime) * 100,
					decodeBottleneckFactor: Math.max(
						theoreticalDecodeTime / actualDecodeTime,
						decodeBandwidthLimitedTime / actualDecodeTime
					)
				};
			});
		}

        function updateSystemAnalysis() {
            const metrics = calculateMetrics();
            console.log(metrics);
            const analysisContainer = document.getElementById('systemAnalysis');
            let systemAnalysisHtml = '';
            metrics.forEach(m => {
                systemAnalysisHtml += `
                    <div style="margin-bottom: 1rem;">
                        <h3>${m.name}</h3>
                        <div class="device-grid" style="font-size: 0.875rem;">
                            <div>Memory Usage: ${m.memoryUtilization.toFixed(1)}%</div>
                            <div>Compute Usage: ${m.computeUtilization.toFixed(1)}%</div>
                            <div>Local BW Usage: ${m.localBandwidthUtilization.toFixed(1)}%</div>
                            <div>Network BW Usage: ${m.networkBandwidthUtilization.toFixed(1)}%</div>
                            <div><strong>Prefill Token Rate (approx.):</strong> ${m.prefillTokensPerSecond.toFixed(2)} tokens/second</div>
                            <div><strong>Decode Token Rate (approx.):</strong> ${m.decodeTokensPerSecond.toFixed(2)} tokens/second</div>
                        </div>
                `;
                // Determine bottleneck for reporting
                let bottleneckType = "None";
                let bottleneckValue = 1;
                if (m.isBottleneck) {
                    if (m.computeUtilization > bottleneckValue) {
                        bottleneckType = "Compute";
                        bottleneckValue = m.computeUtilization;
                    }
                    if (m.memoryUtilization > bottleneckValue) {
                        bottleneckType = "Memory";
                        bottleneckValue = m.memoryUtilization;
                    }
                    if (m.localBandwidthUtilization > bottleneckValue) {
                        bottleneckType = "Local Bandwidth";
                        bottleneckValue = m.localBandwidthUtilization;
                    }
                    if (m.networkBandwidthUtilization > bottleneckValue) {
                        bottleneckType = "Network Bandwidth";
                        bottleneckValue = m.networkBandwidthUtilization;
                    }
                    systemAnalysisHtml += `
                        <div style="color: #ff4444; font-size: 0.875rem; margin-top: 0.5rem;">
                            Prefill performance limited by <strong><span class="math-inline">${bottleneckType}</strong\> constraints (</span>${m.bottleneckFactor.toFixed(1)}x slower)
                        </div>
                    `;
                }
                // Decode bottleneck (simplified for reporting)
                if (m.decodeBottleneckFactor > 1) {
                    let decodeBottleneckType = "None";
                    if (m.decodeComputeUtilization > m.decodeLocalBandwidthUtilization) {
                        decodeBottleneckType = "Compute";
                    } else {
                        decodeBottleneckType = "Local Bandwidth";
                    }
                    systemAnalysisHtml += `
                        <div style="color: #ff4444; font-size: 0.875rem; margin-top: 0.5rem;">
                            Decode performance limited by <strong><span class="math-inline">\{decodeBottleneckType\}</strong\> constraints \(</span>{m.decodeBottleneckFactor.toFixed(1)}x slower)
                        </div>
                    `;
                }
                systemAnalysisHtml += `</div>`;
            });
            analysisContainer.innerHTML = systemAnalysisHtml;
            updateAlerts(metrics);
            updateChart(metrics);
        }
        function updateDeviceDisplay() {
			const currentQuant = document.getElementById('quantizationType').value;
			const devicesContainer = document.getElementById('devices');
			devicesContainer.innerHTML = devices.map(device => `
				<div class="device">
					<div style="display: flex; justify-content: space-between; margin-bottom: 0.5rem;">
						<input class="input" style="width: auto;" value="${device.name}"
							   onchange="updateDevice(${device.id}, 'name', this.value)">
						<button class="button button-destructive"
								onclick="removeDevice(${device.id})"
								${devices.length === 1 ? 'disabled' : ''}>
							Remove
						</button>
					</div>
					<select class="input" onchange="updateDevice(${device.id}, 'template', this.value)">
						${Object.keys(DEVICE_TEMPLATES).map(template => `
							<option value="${template}" ${device.template === template ? 'selected' : ''}>
								${DEVICE_TEMPLATES[template].name}
							</option>
						`).join('')}
					</select>
					<div class="device-grid">
						<div>
							<label>Memory GB</label>
							<input type="number" class="input" value="${device.memoryGB}"
								   onchange="updateDevice(${device.id}, 'memoryGB', parseFloat(this.value) || 0)"
								   ${device.template !== 'Custom' ? 'disabled' : ''}>
						</div>
						<div>
							<label>Local Bandwidth GBps</label>
							<input type="number" class="input" value="${device.localBandwidthGBps}"
								   onchange="updateDevice(${device.id}, 'localBandwidthGBps', parseFloat(this.value) || 0)"
								   ${device.template !== 'Custom' ? 'disabled' : ''}>
						</div>
						<div>
							<label>Network Bandwidth GBps</label>
							<input type="number" class="input" value="${device.networkBandwidthGBps}"
								   onchange="updateDevice(${device.id}, 'networkBandwidthGBps', parseFloat(this.value) || 0)"
								   ${device.template !== 'Custom' ? 'disabled' : ''}>
						</div>
						<div>
							<label>Compute TFlops (${currentQuant})</label>
							<input type="number" class="input" value="${device.computeTFlops[currentQuant]}"
								   onchange="updateDevice(${device.id}, 'computeTFlops', parseFloat(this.value) || 0)"
								   ${device.template !== 'Custom' ? 'disabled' : ''}>
						</div>
					</div>
				</div>
			`).join('');
		}

        function updateAlerts(metrics) {
            const alertsContainer = document.getElementById('alerts');
            let alertsHtml = '';
            if (metrics.some(m => m.isBottleneck)) {
                alertsHtml += `
                    <div class="alert">
                        <div style="font-weight: 600; margin-bottom: 0.5rem;">
                            Configuration Issues:
                        </div>
                        ${metrics.filter(m => m.isBottleneck).map(m => `
                            <div style="margin-left: 1rem;">
                                • ${m.name}:
                                ${m.memoryUtilization > 100 ?
                    ` Requires ${(m.memoryUtilization / 100).toFixed(1)}x more memory` : ''}
                                ${m.localBandwidthUtilization > 100 ?
                    ` Requires ${(m.localBandwidthUtilization / 100).toFixed(1)}x more local bandwidth` : ''}
                                ${m.networkBandwidthUtilization > 100 && getModelConfig().parallelismStrategy === 'pipeline' ?
                    ` Requires ${(m.networkBandwidthUtilization / 100).toFixed(1)}x more network bandwidth` : ''}
                                ${m.computeUtilization > 100 ?
                    ` Requires ${(m.computeUtilization / 100).toFixed(1)}x more compute` : ''}
                            </div>
                        `).join('')}
                    </div>
                `;
            }
            alertsContainer.innerHTML = alertsHtml;
                }
        function updateChart(metrics) {
            const ctx = document.getElementById('utilizationChart').getContext('2d');
            const chartData = {
                labels: metrics.map(m => m.name),
                datasets: [
                    {
                        label: 'Memory',
                        data: metrics.map(m => m.memoryUtilization),
                        backgroundColor: '#8884d8'
                    },
                    {
                        label: 'Local Bandwidth',
                        data: metrics.map(m => m.localBandwidthUtilization),
                        backgroundColor: '#82ca9d'
                    },
                    {
                        label: 'Network Bandwidth',
                        data: metrics.map(m => m.networkBandwidthUtilization),
                        backgroundColor: '#ffc658'
                    },
                    {
                        label: 'Compute',
                        data: metrics.map(m => m.computeUtilization),
                        backgroundColor: '#ff7300'
                    }
                ]
            };
            if (utilizationChart) {
                utilizationChart.destroy();
            }
            utilizationChart = new Chart(ctx, {
                type: 'bar',
                data: chartData,
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    scales: {
                        y: {
                            beginAtZero: true,
                            max: 120,
                            title: {
                                display: true,
                                text: 'Utilization %'
                            }
                        }
                    },
                    plugins: {
                        tooltip: {
                            callbacks: {
                                label: function (context) {
                                    const index = context.dataIndex;
                                    const metric = metrics[index];
                                    const datasetLabel = context.dataset.label;
                                    let actualValue, rawValue;
                                    switch (datasetLabel) {
                                        case 'Memory':
                                            actualValue = metric.memoryUtilization;
                                            rawValue = metric.rawMemoryUtilization;
                                            break;
                                        case 'Local Bandwidth':
                                            actualValue = metric.localBandwidthUtilization;
                                            rawValue = metric.rawLocalBandwidthUtilization;
                                            break;
                                        case 'Network Bandwidth':
                                            actualValue = metric.networkBandwidthUtilization;
                                            rawValue = metric.rawNetworkBandwidthUtilization;
                                            break;
                                        case 'Compute':
                                            actualValue = metric.computeUtilization;
                                            rawValue = metric.rawComputeUtilization;
                                            break;
                                    }
                                    if (rawValue !== actualValue) {
                                        return `${datasetLabel}: ${actualValue.toFixed(1)}% (theoretical max: ${rawValue.toFixed(1)}%)`;
                                    }
                                    return `${datasetLabel}: ${actualValue.toFixed(1)}%`;
                                }
                            }
                        }
                    }
                }
            });
        }
        function addDevice() {
            const lastDevice = devices[devices.length - 1];
            const newDevice = {
                id: devices.length + 1,
                name: `Device ${devices.length + 1}`,
                template: lastDevice.template,
                ...DEVICE_TEMPLATES[lastDevice.template === 'Custom' ? 'Custom' : lastDevice.template],
                memoryGB: lastDevice.memoryGB,
                localBandwidthGBps: lastDevice.localBandwidthGBps,
                networkBandwidthGBps: lastDevice.networkBandwidthGBps,
                computeTFlops: lastDevice.computeTFlops
            };
            devices.push(newDevice);
            updateDeviceDisplay();
            updateSystemAnalysis();
        }
        function removeDevice(id) {
            if (devices.length > 1) {
                devices = devices.filter(d => d.id !== id);
                updateDeviceDisplay();
                updateSystemAnalysis();
            }
        }
		function updateDevice(id, field, value) {
			devices = devices.map(d => {
				if (d.id !== id) return d;
				
				let updatedDevice = { ...d };
				
				if (field === 'template' && value !== 'Custom') {
					// Update entire device with template
					updatedDevice = { ...updatedDevice, ...DEVICE_TEMPLATES[value] };
				} else if (field === 'computeTFlops') {
					// For custom devices, use the entered value as base and scale for other precisions
					const currentQuant = document.getElementById('quantizationType').value;
					const baseValue = value / {
						'float32': 1,
						'bfloat16': 2,
						'float16': 2,
						'int8': 4,
						'q4': 6
					}[currentQuant];

					updatedDevice.computeTFlops = {
						'float32': baseValue,
						'bfloat16': baseValue * 2,
						'float16': baseValue * 2,
						'int8': baseValue * 4,
						'q4': baseValue * 6
					};
				} else {
					updatedDevice[field] = value;
				}
				
				return updatedDevice;
			});
			
			updateDeviceDisplay();
			updateSystemAnalysis();
		}
        function updateModelConfigFromPreset() {
            const modelPresetId = document.getElementById('modelPreset').value;
            const quantizationType = document.getElementById('quantizationType').value;
            if (modelPresetId && MODEL_PRESETS[modelPresetId] && MODEL_PRESETS[modelPresetId][quantizationType]) {
                const preset = MODEL_PRESETS[modelPresetId][quantizationType];
                for (const key in preset) {
                    if (document.getElementById(key)) {
                        document.getElementById(key).value = preset[key];
                    }
                }
            } else if (modelPresetId === "") {
                for (const key in MODEL_PRESETS['llama3_8b']['q4']) {
                    if (document.getElementById(key)) {
                        document.getElementById(key).value = '';
                    }
                }
            }
            updateSystemAnalysis();
        }


        document.getElementById('modelPreset').addEventListener('change', updateModelConfigFromPreset);
        document.getElementById('quantizationType').addEventListener('change', () => {
			// Update display for custom devices
			updateDeviceDisplay();
			updateSystemAnalysis();
		});
        document.querySelectorAll('#modelConfig input, #modelConfig select').forEach(input => {
            if (input.id !== 'modelPreset' && input.id !== 'quantizationType' && input.id !== 'dtype') {
                input.addEventListener('change', updateSystemAnalysis);
            }
        });
		updateModelConfigFromPreset();
        updateDeviceDisplay();
        updateSystemAnalysis();
		
		        const rawData = `Model	Quantization	Framework	Hardware	Batch Size	Sequence Length	Token Rate (Batch)	Token Rate (Single)	Source
Llama 3.1 8b	FP16		Groq				100 t/s	https://www.vellum.ai/llm-leaderboard
Llama 3.1 70b	FP16		Groq				40 t/s	https://www.vellum.ai/llm-leaderboard
Llama 3.1 405b	FP16		Groq				10 t/s	https://www.vellum.ai/llm-leaderboard
Claude 3 Opus					4096		25 t/s	https://www.vellum.ai/llm-leaderboard
GPT-4					8192		125 t/s	https://www.vellum.ai/llm-leaderboard
Claude 3.5 Sonnet						170.4 t/s		https://yourgpt.ai/tools/llm-comparison-and-leaderboard
llama3-8b			SambaNova's RDU (Reconfigurable Dataflow Unit) system with 8-chips		4096	430 t/s		https://blog.lancedb.com/tokens-per-second-is-not-all-you-need/
Mistral 7B	FP16	vLLM	A10G	1			30.9 t/s	https://lightning.ai/lightning-ai/studios/optimized-llm-inference-api-for-mistral-7b-using-vllm
Mistral 7B	FP16	vLLM	4 x A10G	1			64.5 t/s	https://lightning.ai/lightning-ai/studios/optimized-llm-inference-api-for-mistral-7b-using-vllm
Mistral 7B	AWQ 4-bit	vLLM	A10G	1			86.1 t/s	https://lightning.ai/lightning-ai/studios/optimized-llm-inference-api-for-mistral-7b-using-vllm
Mistral 7B	FP16			1	80x100		170 t/s	https://www.baseten.co/blog/benchmarking-fast-mistral-7b-inference/
Mistral-8x7B	Q8_0		RTX 4090				6.55 t/s	https://www.reddit.com/r/LocalLLaMA/comments/18jslmf/tokens_per_second_mistral_8x7b_performance/
Mistral-8x7B	Q5_K_M		RTX 4090				13.16 t/s	https://www.reddit.com/r/LocalLLaMA/comments/18jslmf/tokens_per_second_mistral_8x7b_performance/
Mistral-8x7B	Q4_K_M		RTX 4090				23.06 t/s	https://www.reddit.com/r/LocalLLaMA/comments/18jslmf/tokens_per_second_mistral_8x7b_performance/
Mistral-8x7B	Q8_0		AMD 7950X3D				3.95 t/s	https://www.reddit.com/r/LocalLLaMA/comments/18jslmf/tokens_per_second_mistral_8x7b_performance/
Mistral-8x7B	Q4_K_M		2 x RTX 3090				48.26 t/s	https://www.reddit.com/r/LocalLLaMA/comments/18jslmf/tokens_per_second_mistral_8x7b_performance/
Mistral 7B	Q4		Raspberry Pi 5				2 t/s	https://dmatora.github.io/LLM-inference-speed-benchmarks/
Mistral 7B	Q4		i7-7700HQ (CPU)				3 t/s	https://dmatora.github.io/LLM-inference-speed-benchmarks/
Mistral 7B	Q4		Apple M1 (CPU)				12 t/s	https://dmatora.github.io/LLM-inference-speed-benchmarks/
Mistral 7B	Q4		RTX 4060 Ti				44 t/s	https://dmatora.github.io/LLM-inference-speed-benchmarks/
Mistral 7B	Q4		Tesla P40				45 t/s	https://dmatora.github.io/LLM-inference-speed-benchmarks/
Mistral 7B	Q4		Apple M1 Max (CPU)				58 t/s	https://dmatora.github.io/LLM-inference-speed-benchmarks/
Mistral 7B	Q4		Nvidia RTX 3060				59 t/s	https://dmatora.github.io/LLM-inference-speed-benchmarks/
Mistral 7B	Q4		Apple M1 Ultra (CPU)				70 t/s	https://dmatora.github.io/LLM-inference-speed-benchmarks/
Mistral 7B	Q4		Nvidia RTX 4070				70 t/s	https://dmatora.github.io/LLM-inference-speed-benchmarks/
Mistral 7B	Q4		Nvidia RTX 3090				120 t/s	https://dmatora.github.io/LLM-inference-speed-benchmarks/
Mistral 7B	Q4		Nvidia RTX 4090				140 t/s	https://dmatora.github.io/LLM-inference-speed-benchmarks/
Llama 2 70B	FP16		2 x Tesla P40				3 t/s	https://dmatora.github.io/LLM-inference-speed-benchmarks/
Llama 2 70B	Q4		Apple M1 Max (CPU)				6 t/s	https://dmatora.github.io/LLM-inference-speed-benchmarks/
CodeLlama 70B	Q5_K_M	llama.cpp	Apple M2 Ultra (CPU)				8.72 t/s	https://obrienlabs.medium.com/running-the-70b-llama-2-llm-locally-on-metal-via-llama-cpp-on-mac-studio-m2-ultra-32b3179e9cbe
Llama 2 7B	FP16	vLLM	NVIDIA H100 SXM	1	2048	1000 t/s		https://blog.ori.co/benchmarking-llama-3.1-8b-instruct-on-nvidia-h100-and-a100-chips-with-the-vllm-inferencing-engine
Llama 2 7B	FP16	vLLM	NVIDIA A100	1	2048	500 t/s		https://blog.ori.co/benchmarking-llama-3.1-8b-instruct-on-nvidia-h100-and-a100-chips-with-the-vllm-inferencing-engine
GPT-J 6B	FP8	TensorRT-LLM	NVIDIA H100	64	128	10,907 t/s		https://nvidia.github.io/TensorRT-LLM/blogs/H100vsA100.html
GPT-J 6B	FP16	TensorRT-LLM	NVIDIA A100	64	128	3,679 t/s		https://nvidia.github.io/TensorRT-LLM/blogs/H100vsA100.html
DeepSeek V3	FP16		NVIDIA H800 x 2048					https://www.infoq.com/news/2025/01/deepseek-v3-llm/`;

        const data = rawData.split('\n')
            .filter(line => line.trim())
            .map(line => {
                const [model, quantization, framework, hardware, batchSize, seqLength, tokenRateBatch, tokenRateSingle, source] = line.split('\t');
                return {
                    model, quantization, framework, hardware, batchSize, 
                    seqLength, tokenRateBatch, tokenRateSingle, source
                };
            });

        // Function to render the table
        const renderTable = (data) => {
            const tbody = document.querySelector('#llmTable tbody');
            tbody.innerHTML = '';
            
            data.forEach(row => {
                const tr = document.createElement('tr');
                Object.values(row).forEach(value => {
                    const td = document.createElement('td');
                    td.textContent = value || '';
                    if (value && value.startsWith('http')) {
                        const a = document.createElement('a');
                        a.href = value;
                        a.textContent = 'Link';
                        a.target = '_blank';
                        td.textContent = '';
                        td.appendChild(a);
                    }
                    tr.appendChild(td);
                });
                tbody.appendChild(tr);
            });
        };

        // Sorting function
        const sortTable = (column, direction = 'asc') => {
            const sortedData = [...data].sort((a, b) => {
                let aVal = a[column] || '';
                let bVal = b[column] || '';
                
                // Extract numerical values from strings like "100 t/s"
                if (aVal.includes('t/s')) {
                    aVal = parseFloat(aVal.replace(' t/s', '').replace(',', ''));
                }
                if (bVal.includes('t/s')) {
                    bVal = parseFloat(bVal.replace(' t/s', '').replace(',', ''));
                }
                
                // Convert to numbers if possible
                if (!isNaN(aVal) && !isNaN(bVal)) {
                    aVal = parseFloat(aVal);
                    bVal = parseFloat(bVal);
                }
                
                if (direction === 'asc') {
                    return aVal > bVal ? 1 : -1;
                } else {
                    return aVal < bVal ? 1 : -1;
                }
            });
            
            renderTable(sortedData);
        };

        // Filtering function
        const filterTable = () => {
            const modelFilter = document.getElementById('modelFilter').value.toLowerCase();
            const hardwareFilter = document.getElementById('hardwareFilter').value.toLowerCase();
            const quantizationFilter = document.getElementById('quantizationFilter').value.toLowerCase();

            const filteredData = data.filter(row => {
                return (!modelFilter || row.model.toLowerCase().includes(modelFilter)) &&
                       (!hardwareFilter || (row.hardware && row.hardware.toLowerCase().includes(hardwareFilter))) &&
                       (!quantizationFilter || (row.quantization && row.quantization.toLowerCase().includes(quantizationFilter)));
            });

            renderTable(filteredData);
        };

        // Event listeners
        document.querySelectorAll('th[data-sort]').forEach(th => {
            th.addEventListener('click', () => {
                const column = th.dataset.sort;
                const currentDirection = th.classList.contains('asc') ? 'desc' : 'asc';
                
                // Remove all sort indicators
                document.querySelectorAll('th').forEach(el => {
                    el.classList.remove('asc', 'desc');
                });
                
                th.classList.add(currentDirection);
                sortTable(column, currentDirection);
            });
        });

        document.getElementById('modelFilter').addEventListener('input', filterTable);
        document.getElementById('hardwareFilter').addEventListener('input', filterTable);
        document.getElementById('quantizationFilter').addEventListener('input', filterTable);

        // Initialize table
        renderTable(data);
    </script>
</body>
</html>
